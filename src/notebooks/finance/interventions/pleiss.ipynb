{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Withholding by Pleiss et al. - Adult data\n",
    "\n",
    "This notebook contains the implementation of the post-processing algorithm introduced in [On fairness and calibration](https://dl.acm.org/doi/10.5555/3295222.3295319) by Pleiss et al. (2017) as part of the IBM AIF360 fairness tool box github.com/IBM/AIF360.\n",
    "\n",
    "The migitation method achieves a relaxed version of Equalised Odds while maintaining Calibration by withholding information. In particular a proportion of the advantaged group is predicted according to the base rate without considering the model inputs. This preserves Calibration but allows us to bring the error rates for the two classes closer together.\n",
    "\n",
    "This method is attractive in that it achieves one notion of fairness and approximately achieves another. However, like the intervention of Hardt et al. it introduces randomness into decision making that might not be compatible with individual notions of fairness. Furthermore the method requires as input calibrated classifiers, it does not offer a way to achieve Calibration, only to preserve it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import (\n",
    "    CalibratedEqOddsPostprocessing,\n",
    ")\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from helpers.metrics import accuracy, calibration_difference\n",
    "from helpers.plot import calibration_curves, group_bar_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from helpers import export_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We have committed preprocessed data to the repository for reproducibility and we load it here. Check out hte preprocessing notebook for details on how this data was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# override data_dir in source notebook\n",
    "# this is stripped out for the hosted notebooks\n",
    "artifacts_dir = Path(\"../../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"adult\"\n",
    "\n",
    "train = pd.read_csv(data_dir / \"processed\" / \"train-one-hot.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val-one-hot.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test-one-hot.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process data for our fairness intervention we need to define special dataset objects which are part of every intervention pipeline within the IBM AIF360 toolbox. These objects contain the original data as well as some useful further information, e.g., which feature is the protected attribute as well as which column corresponds to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "index = train_sds.feature_names.index(\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which binary value goes with the (un-)privileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"sex\": 1.0}]\n",
    "unprivileged_groups = [{\"sex\": 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original model\n",
    "\n",
    "For maximum reproducibility we can also load the baseline model from disk, but the code used to train can be found in the baseline model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = joblib.load(\n",
    "    artifacts_dir / \"models\" / \"finance\" / \"baseline.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_test_probs = baseline_model.predict_proba(test.drop(\"salary\", axis=1))[:, 1]\n",
    "test_sds_pred = test_sds.copy(deepcopy=True)\n",
    "test_sds_pred.scores = bl_test_probs.reshape(-1, 1)\n",
    "bl_test_pred = bl_test_probs > 0.5\n",
    "\n",
    "bl_val_probs = baseline_model.predict_proba(val.drop(\"salary\", axis=1))[:, 1]\n",
    "val_sds_pred = val_sds.copy(deepcopy=True)\n",
    "val_sds_pred.scores = bl_val_probs.reshape(-1, 1)\n",
    "bl_val_pred = bl_val_probs > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal opportunity\n",
    "\n",
    "We first address equal opportunity which is achieved by setting the cost_contraint parameter method accordingly when setting up the intervention. We then learn the intervention procedure based on the true and predicted labels of the validation data. Subsequently, we apply the learnt intervention to the predictions of the test data and analyse the outcomes for fairness and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_constraint = \"fnr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters to equal opportunity and apply to create a new dataset\n",
    "cpp = CalibratedEqOddsPostprocessing(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    cost_constraint=cost_constraint,\n",
    "    seed=np.random.seed(),\n",
    ")\n",
    "cpp = cpp.fit(val_sds, val_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply intervention to testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sds_pred_tranf = cpp.predict(test_sds_pred)\n",
    "test_probs = test_sds_pred_tranf.scores.flatten()\n",
    "test_pred = test_probs > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse accuracy and fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_acc = accuracy(test.salary, bl_test_pred)\n",
    "acc = accuracy(test.salary, test_pred)\n",
    "\n",
    "bl_eo = equalized_odds_difference(\n",
    "    test.salary, bl_test_pred, sensitive_features=test.sex,\n",
    ")\n",
    "eo = equalized_odds_difference(\n",
    "    test.salary, test_pred, sensitive_features=test.sex,\n",
    ")\n",
    "\n",
    "bl_calib = calibration_difference(test.salary, bl_test_probs, test.sex)\n",
    "calib = calibration_difference(test.salary, test_probs, test.sex)\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_acc:.3f}\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "print(f\"Baseline equalised odds difference: {bl_eo:.3f}\")\n",
    "print(f\"Equalised odds difference: {eo:.3f}\")\n",
    "\n",
    "print(f\"Baseline calibration: {bl_calib:.3f}\")\n",
    "print(f\"Calibration: {calib:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_curves(\n",
    "    test.salary,\n",
    "    bl_test_probs,\n",
    "    test.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    title=\"Calibration by sex\",\n",
    "    xlabel=\"Score\",\n",
    "    ylabel=\"Proportion positive outcome\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibration is mostly preserved by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_curves(\n",
    "    test.salary,\n",
    "    test_probs,\n",
    "    test.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    title=\"Calibration by sex\",\n",
    "    xlabel=\"Score\",\n",
    "    ylabel=\"Proportion positive outcome\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test.salary == 1\n",
    "\n",
    "eopp_bar = group_bar_plots(\n",
    "    np.concatenate([bl_test_probs[mask], test_probs[mask]]),\n",
    "    np.tile(test.sex[mask].map({0: \"Female\", 1: \"Male\"}), 2),\n",
    "    groups=np.concatenate(\n",
    "        [np.zeros_like(bl_test_probs[mask]), np.ones_like(test_probs[mask])]\n",
    "    ),\n",
    "    group_names=[\"Baseline\", \"Pleiss\"],\n",
    "    title=\"Mean scores for high earners by sex\",\n",
    "    xlabel=\"Mean score\",\n",
    "    ylabel=\"Method\",\n",
    ")\n",
    "eopp_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(eopp_bar, \"pleiss-eopp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalised odds\n",
    "\n",
    "We'll now repeat the process for equalised odds, which requires us changing the underlying cost constraint parameter accordingly, so that the resulting intervention minimises a weighted average between false negative and false positive rate. There are no further parameter choices to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_constraint = \"weighted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn intervention on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "cpp = CalibratedEqOddsPostprocessing(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    cost_constraint=cost_constraint,\n",
    "    seed=np.random.seed(),\n",
    ")\n",
    "cpp = cpp.fit(test_sds, test_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply intervention on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sds_pred_tranf = cpp.predict(test_sds_pred)\n",
    "test_probs = test_sds_pred_tranf.scores.flatten()\n",
    "test_pred = test_probs > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse fairness and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_acc = accuracy(test.salary, bl_test_pred)\n",
    "acc = accuracy(test.salary, test_pred)\n",
    "\n",
    "bl_eo = equalized_odds_difference(\n",
    "    test.salary, bl_test_pred, sensitive_features=test.sex,\n",
    ")\n",
    "eo = equalized_odds_difference(\n",
    "    test.salary, test_pred, sensitive_features=test.sex,\n",
    ")\n",
    "\n",
    "bl_calib = calibration_difference(test.salary, bl_test_probs, test.sex)\n",
    "calib = calibration_difference(test.salary, test_probs, test.sex,)\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_acc:.3f}\")\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "print(f\"Baseline equalised odds difference: {bl_eo:.3f}\")\n",
    "print(f\"Equalised odds difference: {eo:.3f}\")\n",
    "\n",
    "print(f\"Baseline calibration: {bl_calib:.3f}\")\n",
    "print(f\"Calibration: {calib:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we find that imposing equalised odds does not work so well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_curves(\n",
    "    test.salary,\n",
    "    test_probs,\n",
    "    test.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    title=\"Calibration by sex\",\n",
    "    xlabel=\"Score\",\n",
    "    ylabel=\"Proportion positive outcome\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_eo_bar = group_bar_plots(\n",
    "    bl_test_probs,\n",
    "    test.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    groups=np.concatenate(\n",
    "        [\n",
    "            np.zeros_like(bl_test_probs[~mask]),\n",
    "            np.ones_like(bl_test_probs[mask]),\n",
    "        ]\n",
    "    ),\n",
    "    group_names=[\"Low earners\", \"High earners\"],\n",
    "    title=\"Mean scores by sex\",\n",
    "    xlabel=\"Mean score\",\n",
    "    ylabel=\"Method\",\n",
    ")\n",
    "bl_eo_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_bar = group_bar_plots(\n",
    "    test_probs,\n",
    "    test.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    groups=np.concatenate(\n",
    "        [\n",
    "            np.zeros_like(test_probs[~mask]),\n",
    "            np.ones_like(test_probs[mask]),\n",
    "        ]\n",
    "    ),\n",
    "    group_names=[\"Low earners\", \"High earners\"],\n",
    "    title=\"Mean scores by sex\",\n",
    "    xlabel=\"Mean score\",\n",
    "    ylabel=\"Method\",\n",
    ")\n",
    "eo_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(bl_eo_bar, \"pleiss-bl-eo.json\")\n",
    "export_plot(eo_bar, \"pleiss-eo.json\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
