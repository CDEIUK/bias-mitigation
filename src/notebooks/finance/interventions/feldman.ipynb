{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certifying and Removing Disparate Impact\n",
    "\n",
    "This notebook apples the algorithm described in [Certifying and removing disparate impact](https://dl.acm.org/doi/10.1145/2783258.2783311) by Feldman et al., as implemented by the [AI Fairness 360 library](https://aif360.readthedocs.io/) from IBM.\n",
    "\n",
    "This is a pre-processing algorithm that works by adjusting the distributions of the features conditional on the protected attribute to be equal, so that a subsequently trained model can't discriminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,\n",
    "    demographic_parity_ratio,\n",
    ")\n",
    "from helpers.plot import group_box_plots\n",
    "from sklearn.neural_network import MLPClassifier  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from helpers import export_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We have committed preprocessed data to the repository for reproducibility and we load it here. Check out the preprocessing notebook for details on how this data was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# override data_dir in source notebook\n",
    "# this is stripped out for the hosted notebooks\n",
    "artifacts_dir = Path(\"../../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"adult\"\n",
    "\n",
    "train_oh = pd.read_csv(data_dir / \"processed\" / \"train-one-hot.csv\")\n",
    "val_oh = pd.read_csv(data_dir / \"processed\" / \"val-one-hot.csv\")\n",
    "test_oh = pd.read_csv(data_dir / \"processed\" / \"test-one-hot.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`aif360` uses the following custom dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train_oh,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val_oh,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test_oh,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "index = train_sds.feature_names.index(\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train unfair model\n",
    "\n",
    "For maximum reproducibility we load the baseline model from disk, but the code used to train can be found in the baseline model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_model = joblib.load(artifacts_dir / \"models\" / \"finance\" / \"baseline.pkl\")\n",
    "\n",
    "bl_test_probs = bl_model.predict_proba(test_sds.features)[:, 1]\n",
    "bl_test_pred = bl_test_probs > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform intervention\n",
    "\n",
    "We repair the dataset using the `DisparateImpactRemover`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "di = DisparateImpactRemover(repair_level=1.0)\n",
    "\n",
    "train_repd = di.fit_transform(train_sds)\n",
    "train_repd_X = np.delete(train_repd.features, index, axis=1)\n",
    "train_repd_y = train_repd.labels.flatten()\n",
    "\n",
    "test_repd = di.fit_transform(test_sds)\n",
    "test_repd_X = np.delete(test_repd.features, index, axis=1)\n",
    "test_repd_y = test_repd.labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on fair data\n",
    "\n",
    "We use the same architecture, but the repaired data. Once again we load a trained model for reproducibility, but the code used to train the model can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(artifacts_dir / \"models\" / \"finance\" / \"feldman.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLPClassifier(hidden_layer_sizes=(100, 100), early_stopping=True)\n",
    "# model.fit(train_repd_X, train_repd_y)\n",
    "\n",
    "test_probs = model.predict_proba(test_repd_X)[:, 1]\n",
    "test_pred = test_probs > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse unfairness and accuracy\n",
    "\n",
    "We measure the accuracy and fairness in baseline and compare it to the corrected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_acc = bl_model.score(test_oh.drop(columns=\"salary\"), test_oh.salary)\n",
    "bl_dpd = demographic_parity_difference(\n",
    "    test_oh.salary,\n",
    "    bl_test_pred,\n",
    "    sensitive_features=test_oh.sex,\n",
    ")\n",
    "bl_dpr = demographic_parity_ratio(\n",
    "    test_oh.salary,\n",
    "    bl_test_pred,\n",
    "    sensitive_features=test_oh.sex,\n",
    ")\n",
    "\n",
    "acc = model.score(test_repd_X, test_oh.salary)\n",
    "dpd = demographic_parity_difference(\n",
    "    test_oh.salary,\n",
    "    test_pred,\n",
    "    sensitive_features=test_oh.sex,\n",
    ")\n",
    "dpr = demographic_parity_ratio(\n",
    "    test_oh.salary,\n",
    "    test_pred,\n",
    "    sensitive_features=test_oh.sex,\n",
    ")\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_acc:.3f}\")\n",
    "print(f\"Accuracy: {acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline demographic parity difference: {bl_dpd:.3f}\")\n",
    "print(f\"Demographic parity difference: {dpd:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline demographic parity ratio: {bl_dpr:.3f}\")\n",
    "print(f\"Demographic parity ratio: {dpr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the disparity between men and women with a box plot of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_box = group_box_plots(\n",
    "    np.concatenate([bl_test_probs, test_probs]),\n",
    "    np.tile(test_oh.sex.map(lambda x: \"Male\" if x else \"Female\"), 2),\n",
    "    groups=np.concatenate(\n",
    "        [np.zeros_like(bl_test_probs), np.ones_like(test_probs)]\n",
    "    ),\n",
    "    group_names=[\"Baseline\", \"Feldman\"],\n",
    "    title=\"Distribution of scores by sex\",\n",
    "    xlabel=\"Score\",\n",
    "    ylabel=\"Model\",\n",
    "    \n",
    ")\n",
    "dp_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(dp_box, \"feldman-dp.json\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
