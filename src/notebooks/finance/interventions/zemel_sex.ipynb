{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zemel et al. pre-processing fairness intervention\n",
    "\n",
    "Zemel et al. (2013) proposes a clustering method which transforms the original data set by expressing points as linear combinations of learnt cluster centres. The transformed data set is as close as possible to the original while containing as little information as possible about the sensitive attributes. Thereby, demographic parity is achieved.\n",
    "\n",
    "The output of their method includes besides a fair data representation also fair label predictions, which allows the comparison according to the usual fairness metrics. We apply their approach as implemented by IBM's AIF360 fairness tool box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.datasets import StandardDataset\n",
    "from helpers.fairness_measures import *\n",
    "from helpers.finance import preprocess\n",
    "from helpers.plot import group_box_plots, group_roc_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from helpers import export_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# override data_dir in source notebook\n",
    "# this is stripped out for the hosted notebooks\n",
    "artifacts_dir = Path(\"../../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"adult\"\n",
    "preprocess(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir / \"processed\" / \"train-one-hot.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val-one-hot.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test-one-hot.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up fairness intervention\n",
    "AIF360 requires expressing the original data sets via the \"StandardDataset\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "index = train_sds.feature_names.index(\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"sex\": 1.0}]\n",
    "unprivileged_groups = [{\"sex\": 0.0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn fair representation\n",
    "The hyperparameters $A_x, A_y, A_z$ and $k$ are chosen how? According to optimum of a grid search for Adult.\n",
    "\n",
    "NB: Have the number of maximal iterations altered compared to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = joblib.load(artifacts_dir / \"models\" / \"finance\" / \"zemel-sex.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TR = LFR(\n",
    "#     unprivileged_groups=unprivileged_groups,\n",
    "#     privileged_groups=privileged_groups,\n",
    "#     k=5,\n",
    "#     Ax=0.01,\n",
    "#     Ay=1.0,\n",
    "#     Az=25.0,\n",
    "# )\n",
    "# TR = TR.fit(train_sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply transformation to validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_val_sds = TR.transform(val_sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy(transf_val_sds.labels.flatten(), val_sds.labels.flatten())\n",
    "print(\"Accuracy after fairness intervention =\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fair labels\n",
    "val_fair_labels = transf_val_sds.labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy =\", accuracy(val_fair_labels, val.salary))\n",
    "print(\n",
    "    \"Female accuracy =\",\n",
    "    accuracy(val_fair_labels[val.sex == 0], val.salary[val.sex == 0]),\n",
    ")\n",
    "print(\n",
    "    \"Male accuracy =\",\n",
    "    accuracy(val_fair_labels[val.sex == 1], val.salary[val.sex == 1]),\n",
    ")\n",
    "print(\"Mean female score =\", val_fair_labels[val.sex == 0].mean())\n",
    "print(\"Mean male score =\", val_fair_labels[val.sex == 1].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_d = disparate_impact_d(val_fair_labels, val.sex)\n",
    "print(\"Sex demographic parity =\", dp_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dp_bar = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(\n",
    "            x=[sex],\n",
    "            y=[val_fair_labels[val.sex == sex].mean()],\n",
    "            name=\"Male\" if sex else \"Female\",\n",
    "        )\n",
    "        for sex in range(2)\n",
    "    ],\n",
    "    layout={\"yaxis\": {\"range\": [0, 1]}},\n",
    ")\n",
    "dp_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(dp_bar, \"zemel-sex-dp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalised Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go.Figure(\n",
    "#     data=[\n",
    "#         go.Bar(\n",
    "#             x=[label],\n",
    "#             y=[\n",
    "#                 val_fair_labels[\n",
    "#                     (val.sex == sex) & (val.salary == label)\n",
    "#                 ].mean()\n",
    "#             ],\n",
    "#             name=\"Male\" if sex else \"Female\",\n",
    "#         )\n",
    "#         for label in range(2)\n",
    "#         for sex in range(2)\n",
    "#     ]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
