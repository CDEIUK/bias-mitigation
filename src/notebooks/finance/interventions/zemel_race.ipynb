{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zemel et al. pre-processing fairness intervention\n",
    "\n",
    "Zemel et al. (2013) proposes a clustering method which transforms the original data set by expressing points as linear combinations of learnt cluster centres. The transformed data set is as close as possible to the original while containing as little information as possible about the sensitive attributes. Thereby, demographic parity is achieved.\n",
    "\n",
    "The output of their method includes besides a fair data representation also fair label predictions, which allows the comparison according to the usual fairness metrics. We apply their approach as implemented by IBM's AIF360 fairness tool box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "from helpers.fairness_measures import *\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from cdei_helpers.plot import group_box_plots, group_roc_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"/project/data/adult/processed/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/project/data/adult/processed/train-one-hot.csv\").sample(\n",
    "    6000\n",
    ")\n",
    "test = pd.read_csv(\"/project/data/adult/processed/test-one-hot.csv\").sample(\n",
    "    2000\n",
    ")\n",
    "val = pd.read_csv(\"/project/data/adult/processed/val-one-hot.csv\").sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove points which are not white/black people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train, test, val]:\n",
    "    data = data[data.race_white + data.race_black == 1]\n",
    "    data.drop(\n",
    "        [\n",
    "            \"race_amer_indian_eskimo\",\n",
    "            \"race_asian_pac_islander\",\n",
    "            \"race_other\",\n",
    "            \"race_black\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up fairness intervention\n",
    "AIF360 requires expressing the original data sets via the \"StandardDataset\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "index = train_sds.feature_names.index(\"race_white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"race_white\": 1.0}]\n",
    "unprivileged_groups = [{\"race_white\": 0.0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn fair representation\n",
    "The hyperparameters $A_x, A_y, A_z$ and $k$ are chosen how? According to optimum of a grid search for Adult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = LFR(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    k=5,\n",
    "    Ax=0.01,\n",
    "    Ay=1.0,\n",
    "    Az=100.0,\n",
    ")\n",
    "TR = TR.fit(train_sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply transformation to validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_val_sds = TR.transform(val_sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fairness and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fair labels\n",
    "val_fair_labels = transf_val_sds.labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy =\", accuracy(val_fair_labels, val.salary))\n",
    "print(\n",
    "    \"Black accuracy =\",\n",
    "    accuracy(\n",
    "        val_fair_labels[val.race_white == 0], val.salary[val.race_white == 0],\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"White accuracy =\",\n",
    "    accuracy(\n",
    "        val_fair_labels[val.race_white == 1], val.salary[val.race_white == 1],\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"Mean black score =\", val_fair_labels[val.race_white == 0].mean(),\n",
    ")\n",
    "print(\n",
    "    \"Mean white score =\", val_fair_labels[val.race_white == 1].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_d = disparate_impact_d(val_fair_labels, val.race_white)\n",
    "print(\"Race demographic parity =\", di_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    data=[\n",
    "        go.Bar(\n",
    "            x=[race],\n",
    "            y=[val_fair_labels[val.race_white == race].mean()],\n",
    "            name=\"White\" if race else \"Black\",\n",
    "        )\n",
    "        for race in range(2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
