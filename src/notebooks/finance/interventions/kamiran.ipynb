{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label modifcation by Kamiran et al. - Adult data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the implementation of the post-processing label modification algorithm introduced in [Decision Theory for Discrimination-aware Classification](https://ieeexplore.ieee.org/abstract/document/6413831) by Kamiran et al. (2012) as part of the IBM AIF360 fairness tool box github.com/IBM/AIF360.\n",
    "\n",
    "The intervention method identifies a low-confidence subset of the data for probabilistic classifiers, and produces new predicted labels for this subset by assigning positive labels to the unprivileged group and negative labels to the privileged group. Different notions of fairness can be achieved in this way, including demographic parity, equalised odds and equal opportunity, of which each one is allowed in the implementation. In this notebook we demonstrate each of these three definitions as a result of the fairness intervention. \n",
    "\n",
    "For simplicity, we'll focus mitigating bias with resepct to sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import (\n",
    "    RejectOptionClassification,\n",
    ")\n",
    "from helpers.fairness_measures import (\n",
    "    accuracy,\n",
    "    disparate_impact_d,\n",
    "    equalised_odds_d,\n",
    "    equal_opportunity_d,\n",
    ")\n",
    "from helpers.finance import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from helpers import export_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of artifacts (model and data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# override data_dir in source notebook\n",
    "# this is stripped out for the hosted notebooks\n",
    "artifacts_dir = Path(\"../../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"adult\"\n",
    "preprocess(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir / \"processed\" / \"train-one-hot.csv\").sample(6000)\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val-one-hot.csv\").sample(2000)\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test-one-hot.csv\").sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process data for our fairness intervention we need to define special dataset objects which are part of every intervention pipeline within the IBM AIF360 toolbox. These objects contain the original data as well as some useful further information, e.g., which feature is the protected attribute as well as which column corresponds to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which binary value goes with the (un-)privileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"sex\": 1.0}]\n",
    "unprivileged_groups = [{\"sex\": 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce a baseline unfair model, which is trained for performance only and to which the post-processing intervention is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model = MLPClassifier(\n",
    "#     hidden_layer_sizes=(100, 100), early_stopping=True\n",
    "# )\n",
    "# baseline_model.fit(train.drop(\"salary\", axis=1), train.salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For maximum reproducibility we can also load the baseline model from disk, but the code used to train can be found in the baseline model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = joblib.load(\n",
    "    artifacts_dir / \"models\" / \"finance\" / \"baseline.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_val_scores = baseline_model.predict_proba(val.drop(\"salary\", axis=1))[:, 1]\n",
    "val_sds_pred = val_sds.copy(deepcopy=True)\n",
    "val_sds_pred.scores = bl_val_scores.reshape(-1, 1)\n",
    "\n",
    "bl_test_scores = baseline_model.predict_proba(test.drop(\"salary\", axis=1))[\n",
    "    :, 1\n",
    "]\n",
    "test_sds_pred = test_sds.copy(deepcopy=True)\n",
    "test_sds_pred.scores = bl_test_scores.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic parity\n",
    "\n",
    "We first address demographic parity. In order to do so, we learn the label modification algorithm based on the true and predicted labels of the validation data. We then apply the learnt intervention to the predictions of the test data and analyse the outcomes for fairness and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used\n",
    "metric_name = \"Statistical parity difference\"  # Alias for demographic parity\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn intervention\n",
    "\n",
    "On validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    low_class_thresh=0.01,\n",
    "    high_class_thresh=0.99,\n",
    "    num_class_thresh=100,\n",
    "    num_ROC_margin=50,\n",
    "    metric_name=metric_name,\n",
    "    metric_ub=metric_ub,\n",
    "    metric_lb=metric_lb,\n",
    ")\n",
    "ROC = ROC.fit(val_sds, val_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply intervention\n",
    "\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set\n",
    "test_sds_pred_transf = ROC.predict(test_sds_pred).copy(deepcopy=True)\n",
    "test_pred_labels = test_sds_pred_transf.labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse fairness and accuracy\n",
    "\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.drop(columns=[\"sex\", \"salary\"]).values\n",
    "test_sex = test[[\"sex\"]].values.flatten()\n",
    "test_salary = test[\"salary\"].values.flatten()\n",
    "mask = test_sex == 1\n",
    "\n",
    "# baseline metrics\n",
    "bl_test_acc = accuracy(bl_test_scores, test_salary)\n",
    "bl_test_did = disparate_impact_d(bl_test_scores, test_sex)\n",
    "\n",
    "# new model metrics\n",
    "test_acc = accuracy(test_pred_labels, test_salary)\n",
    "test_did = disparate_impact_d(test_pred_labels, test_sex)\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline demographic parity (dist.): {bl_test_did:.3f}\")\n",
    "print(f\"Demographic parity (dist.): {test_did:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider accuracy on the female / male subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Female accuracy =\",\n",
    "    accuracy(test_pred_labels[test.sex == 0], test.salary[test.sex == 0]),\n",
    ")\n",
    "print(\n",
    "    \"Male accuracy =\",\n",
    "    accuracy(test_pred_labels[test.sex == 1], test.salary[test.sex == 1]),\n",
    ")\n",
    "print(\"Mean female score =\", test_pred_labels[test.sex == 0].mean())\n",
    "print(\"Mean male score =\", test_pred_labels[test.sex == 1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_bar = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(\n",
    "            x=[sex],\n",
    "            y=[test_pred_labels[test_sex == sex].mean()],\n",
    "            name=\"Male\" if sex else \"Female\",\n",
    "        )\n",
    "        for sex in range(2)\n",
    "    ]\n",
    ")\n",
    "dp_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(dp_bar, \"kamiran-dp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalised Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now repeat the process for equalised odds, which requires us changing the underlying metric which leads to learning the correction according a new decision threshold addressing equalised odds. There are no further modifcations to the existing parameter choices required. However we apply smaller bounds on equalised odds than for demographic parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used\n",
    "metric_name = \"Average odds difference\"  # alias for equalised odds\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.01\n",
    "metric_lb = -0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn intervention\n",
    "On validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    low_class_thresh=0.01,\n",
    "    high_class_thresh=0.99,\n",
    "    num_class_thresh=100,\n",
    "    num_ROC_margin=50,\n",
    "    metric_name=metric_name,\n",
    "    metric_ub=metric_ub,\n",
    "    metric_lb=metric_lb,\n",
    ")\n",
    "ROC = ROC.fit(val_sds, val_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply intervention\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set\n",
    "test_sds_pred_transf = ROC.predict(test_sds_pred).copy(deepcopy=True)\n",
    "test_pred_labels = test_sds_pred_transf.labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse fairness and accuracy\n",
    "\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.drop(columns=[\"sex\", \"salary\"]).values\n",
    "test_sex = test[[\"sex\"]].values.flatten()\n",
    "test_salary = test[\"salary\"].values.flatten()\n",
    "mask = test_sex == 1\n",
    "\n",
    "# baseline metrics\n",
    "bl_test_acc = accuracy(bl_test_scores, test_salary)\n",
    "bl_test_eod = equalised_odds_d(bl_test_scores, test_sex, test_salary)\n",
    "\n",
    "# new model metrics\n",
    "test_acc = accuracy(test_pred_labels, test_salary)\n",
    "test_eod = equalised_odds_d(test_pred_labels, test_sex, test_salary)\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline equalised odds (dist.): {bl_test_eod:.3f}\")\n",
    "print(f\"Equalised odds (dist.): {test_eod:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_bar = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(\n",
    "            x=[label],\n",
    "            y=[\n",
    "                test_pred_labels[\n",
    "                    (test.sex == sex) & (test.salary == label)\n",
    "                ].mean()\n",
    "            ],\n",
    "            name=\"Male\" if sex else \"Female\",\n",
    "        )\n",
    "        for label in range(2)\n",
    "        for sex in range(2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "eo_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(eo_bar, \"kamiran-eo.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal opportunity\n",
    "We'll now repeat the process for equalised opportunity, which only requires us changing the underlying metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used\n",
    "metric_name = \"Equal opportunity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.01\n",
    "metric_lb = -0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn interrvention\n",
    "On validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    low_class_thresh=0.01,\n",
    "    high_class_thresh=0.99,\n",
    "    num_class_thresh=100,\n",
    "    num_ROC_margin=50,\n",
    "    metric_name=metric_name,\n",
    "    metric_ub=metric_ub,\n",
    "    metric_lb=metric_lb,\n",
    ")\n",
    "ROC = ROC.fit(val_sds, val_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply intervention\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set\n",
    "test_sds_pred_transf = ROC.predict(test_sds_pred).copy(deepcopy=True)\n",
    "test_pred_labels = test_sds_pred_transf.labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse fairness and accuracy\n",
    "\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.drop(columns=[\"sex\", \"salary\"]).values\n",
    "test_sex = test[[\"sex\"]].values.flatten()\n",
    "test_salary = test[\"salary\"].values.flatten()\n",
    "mask = test_sex == 1\n",
    "\n",
    "# baseline metrics\n",
    "bl_test_acc = accuracy(bl_test_scores, test_salary)\n",
    "bl_test_eoppd = equal_opportunity_d(bl_test_scores, test_sex, test_salary)\n",
    "\n",
    "# new model metrics\n",
    "test_acc = accuracy(test_pred_labels, test_salary)\n",
    "test_eoppd = equal_opportunity_d(test_pred_labels, test_sex, test_salary)\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline equalised odds (dist.): {bl_test_eoppd:.3f}\")\n",
    "print(f\"Equalised odds (dist.): {test_eoppd:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopp_bar = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(\n",
    "            x=[sex],\n",
    "            y=[\n",
    "                test_pred_labels[\n",
    "                    (test.sex == sex) & (test.salary == 1.0)\n",
    "                ].mean()\n",
    "            ],\n",
    "            name=\"Male\" if sex else \"Female\",\n",
    "        )\n",
    "        for sex in range(2)\n",
    "    ]\n",
    ")\n",
    "eopp_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(eopp_bar, \"kamiran-eopp.json\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
