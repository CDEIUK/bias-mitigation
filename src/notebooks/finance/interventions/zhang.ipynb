{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial debiasing - Adult data\n",
    "\n",
    "This notebook contains a simple implementations of the algorithm presented in [Mitigating Unwated Biases with Adversarial Learning](https://dl.acm.org/doi/10.1145/3278721.3278779) by Zhang et al.\n",
    "\n",
    "We train a model in tandem with an adversary that tries to predict sensitive data from the model outputs. By training the model not only to perform well, but also to fool the adversary we achieve fairness. By varying what we allow the adversary to see, we can achieve different notions of fairness with an otherwise very similar setup. In this notebook we demonstrate demographic parity, conditional demographic parity and equalised odds.\n",
    "\n",
    "For simplicity, we'll focus mitigating bias with resepct to `sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from helpers.fairness_measures import (\n",
    "    accuracy,\n",
    "    disparate_impact_d,\n",
    "    disparate_impact_p,\n",
    "    equalised_odds_d,\n",
    "    equalised_odds_p,\n",
    ")\n",
    "from helpers.finance import bin_hours_per_week\n",
    "from helpers.plot import group_box_plots\n",
    "from tqdm.auto import tqdm  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from helpers import export_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function normalises numbers to the range $(0, 1)$, and is useful for constraining model outputs to be probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(arr):\n",
    "    return 1 / (1 + np.exp(-arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set some global hyperparameters for easy reference. Feel free to experiment with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "ITERATIONS = 5000\n",
    "WARMUP_ITERATIONS = 2000\n",
    "# number of discriminator training steps per model training step\n",
    "DISCRIMINATOR_STEPS = 5\n",
    "\n",
    "MODEL_HIDDEN_UNITS = [50, 50]\n",
    "MODEL_ACTIVATION = \"relu\"\n",
    "MODEL_LEARNING_RATE = 1e-4\n",
    "\n",
    "DISCRIMINATOR_HIDDEN_UNITS = [50, 50]\n",
    "DISCRIMINATOR_ACTIVATION = \"relu\"\n",
    "DISCRIMINATOR_LEARNING_RATE = 1e-2\n",
    "DISCRIMINATOR_LOSS_WEIGHT = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of artifacts (model and data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# override data_dir in source notebook\n",
    "# this is stripped out for the hosted notebooks\n",
    "artifacts_dir = Path(\"../../../../artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. Check out the preprocessing notebook for details on how this data was obtained. Tensorflow expects float32 data, so we cast all columns on load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"adult\"\n",
    "\n",
    "train_oh = pd.read_csv(data_dir / \"processed\" / \"train-one-hot.csv\").astype(\n",
    "    np.float32\n",
    ")\n",
    "val_oh = pd.read_csv(data_dir / \"processed\" / \"val-one-hot.csv\").astype(\n",
    "    np.float32\n",
    ")\n",
    "test_oh = pd.read_csv(data_dir / \"processed\" / \"test-one-hot.csv\").astype(\n",
    "    np.float32\n",
    ")\n",
    "\n",
    "# unscaled data for making plots\n",
    "train = pd.read_csv(data_dir / \"processed\" / \"train.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create NumPy arrays of relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_oh.drop(columns=[\"sex\", \"salary\"]).values\n",
    "train_sex = train_oh[[\"sex\"]].values\n",
    "train_salary = train_oh[\"salary\"].values\n",
    "\n",
    "val_features = val_oh.drop(columns=[\"sex\", \"salary\"]).values\n",
    "val_sex = val_oh[[\"sex\"]].values\n",
    "val_salary = val_oh[\"salary\"].values\n",
    "\n",
    "test_features = test_oh.drop(columns=[\"sex\", \"salary\"]).values\n",
    "test_sex = test_oh[[\"sex\"]].values\n",
    "test_salary = test_oh[\"salary\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also load the baseline adult model to compare results against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = joblib.load(\n",
    "    artifacts_dir / \"models\" / \"finance\" / \"baseline.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic parity.\n",
    "\n",
    "Build a model and an adversary. We use simple feed-forward networks in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=MODEL_ACTIVATION)\n",
    "        for units in MODEL_HIDDEN_UNITS\n",
    "    ],\n",
    "    name=\"model\",\n",
    ")\n",
    "# no activation in last layer, model outputs logits not probabilities.\n",
    "dp_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "dp_discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=DISCRIMINATOR_ACTIVATION)\n",
    "        for units in DISCRIMINATOR_HIDDEN_UNITS\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "# also no activation function here.\n",
    "dp_discriminator.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline to manage training. This pipeline contains the original model, and feeds the outputs of the model to the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.keras.Input(train_features.shape[1])\n",
    "attribute = tf.keras.Input(1)\n",
    "\n",
    "# concatenate features and protected data to pass to model\n",
    "model_inputs = tf.keras.layers.concatenate([features, attribute])\n",
    "model_outputs = dp_model(model_inputs)\n",
    "\n",
    "# pass model outputs to discriminator\n",
    "discriminator_outputs = dp_discriminator(model_outputs)\n",
    "\n",
    "# pipeline outputs both model and discriminator outputs\n",
    "dp_pipeline = tf.keras.Model(\n",
    "    inputs=[features, attribute],\n",
    "    outputs=[model_outputs, discriminator_outputs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build Tensorflow datasets from the data. These will handle batching and shuffling of the data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((train_features, train_sex), train_salary)\n",
    "    )\n",
    "    .shuffle(buffer_size=BATCH_SIZE * 16, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(((val_features, val_sex), val_salary))\n",
    "    .batch(val_features.shape[0])\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((test_features, test_sex), test_salary)\n",
    "    )\n",
    "    .batch(test_features.shape[0])\n",
    "    .repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function makes the relevant training steps. Since we'll reuse very similar training steps later we make a function that takes as an argument the pipeline and returns the training steps plus metrics that get logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_steps(\n",
    "    pipeline, model_learning_rate, discriminator_learning_rate\n",
    "):\n",
    "    # separate optimisers for the model and discriminator\n",
    "    model_optim = tf.optimizers.Adam(model_learning_rate)\n",
    "    discriminator_optim = tf.optimizers.Adam(discriminator_learning_rate)\n",
    "\n",
    "    # use binary cross entropy for losses, note from_logits=True as we\n",
    "    # have not normalised the model outputs into probabilities.\n",
    "    binary_cross_entropy = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    # lists of variables that will be updated during training.\n",
    "    model_vars = pipeline.get_layer(\"model\").trainable_variables\n",
    "    discriminator_vars = pipeline.get_layer(\n",
    "        \"discriminator\"\n",
    "    ).trainable_variables\n",
    "\n",
    "    # create a dictionary of metrics for easy tracking of losses\n",
    "    metrics = {\n",
    "        \"performance_loss\": tf.metrics.Mean(\n",
    "            \"performance-loss\", dtype=tf.float32\n",
    "        ),\n",
    "        \"val_performance_loss\": tf.metrics.Mean(\n",
    "            \"val-performance-loss\", dtype=tf.float32\n",
    "        ),\n",
    "        \"discriminator_loss\": tf.metrics.Mean(\n",
    "            \"discriminator-loss\", dtype=tf.float32\n",
    "        ),\n",
    "        \"val_discriminator_loss\": tf.metrics.Mean(\n",
    "            \"val-discriminator-loss\", dtype=tf.float32\n",
    "        ),\n",
    "        \"loss\": tf.metrics.Mean(\"loss\", dtype=tf.float32),\n",
    "        \"val_loss\": tf.metrics.Mean(\"val-loss\", dtype=tf.float32),\n",
    "    }\n",
    "\n",
    "    @tf.function\n",
    "    def model_training_step(x_train, y_train, discriminator_loss_weight):\n",
    "        \"\"\"\n",
    "        The weights of the model are trained by minimising.\n",
    "\n",
    "        (1 - dlw) * model_loss - dlw * discriminator_loss\n",
    "\n",
    "        The minus sign in front of the discriminator loss means we try to\n",
    "        maximise it, thereby removing information about the protected\n",
    "        attribute from the model outputs.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            fair_logits, discriminator_logits = pipeline(x_train)\n",
    "            performance_loss = binary_cross_entropy(y_train, fair_logits)\n",
    "            discriminator_loss = binary_cross_entropy(\n",
    "                x_train[1], discriminator_logits\n",
    "            )\n",
    "            loss = (\n",
    "                (1 - discriminator_loss_weight) * performance_loss\n",
    "                - discriminator_loss_weight * discriminator_loss\n",
    "            )\n",
    "\n",
    "        metrics[\"performance_loss\"](performance_loss)\n",
    "        metrics[\"discriminator_loss\"](discriminator_loss)\n",
    "        metrics[\"loss\"](loss)\n",
    "\n",
    "        # compute gradients and pass to optimiser\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        model_optim.apply_gradients(zip(grads, model_vars))\n",
    "\n",
    "    @tf.function\n",
    "    def discriminator_training_step(x_train):\n",
    "        \"\"\"\n",
    "        The weights of the discriminator are simply trained by minimising\n",
    "        the discriminator loss directly.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            _, discriminator_logits = pipeline(x_train)\n",
    "            discriminator_loss = binary_cross_entropy(\n",
    "                x_train[1], discriminator_logits\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(discriminator_loss, discriminator_vars)\n",
    "        discriminator_optim.apply_gradients(zip(grads, discriminator_vars))\n",
    "\n",
    "    @tf.function\n",
    "    def val_step(x_val, y_val, discriminator_loss_weight):\n",
    "        fair_logits, discriminator_logits = pipeline(x_val)\n",
    "        performance_loss = binary_cross_entropy(y_val, fair_logits)\n",
    "        discriminator_loss = binary_cross_entropy(\n",
    "            x_val[1], discriminator_logits\n",
    "        )\n",
    "        loss = (\n",
    "            (1 - discriminator_loss_weight) * performance_loss\n",
    "            - discriminator_loss_weight * discriminator_loss\n",
    "        )\n",
    "\n",
    "        metrics[\"val_performance_loss\"](performance_loss)\n",
    "        metrics[\"val_discriminator_loss\"](discriminator_loss)\n",
    "        metrics[\"val_loss\"](loss)\n",
    "\n",
    "    return model_training_step, discriminator_training_step, val_step, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the training steps for demographic parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    model_training_step,\n",
    "    discriminator_training_step,\n",
    "    val_step,\n",
    "    metrics,\n",
    ") = make_training_steps(\n",
    "    dp_pipeline, MODEL_LEARNING_RATE, DISCRIMINATOR_LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model typically takes a couple of minutes, so we load a trained model from disk here, but all the code used to train the model we're loading is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_pipeline = tf.keras.models.load_model(\n",
    "    artifacts_dir / \"models\" / \"finance\" / \"adversarial-dp.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to train the model. We'll manually track the losses with a list since our setup is not too complicated, but we could also log metrics to [TensorBoard](https://www.tensorflow.org/tensorboard/) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = iter(train_data)\n",
    "# val_ds = iter(val_data)\n",
    "\n",
    "# perf_losses = []\n",
    "# disc_losses = []\n",
    "# losses = []\n",
    "\n",
    "# val_perf_losses = []\n",
    "# val_disc_losses = []\n",
    "# val_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by warming up the model without a fairness constraint to help optimisation later. Since the fairness and performance objectives are in tension, it's helpful to first roughly optimise for performance before brining in the fairness constraint.\n",
    "\n",
    "To train we'll simply loop over the training data and apply the model training step with the discriminator weight set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(WARMUP_ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "#     model_training_step(x_train_batch, y_train_batch, 0.0)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         x_val_batch, y_val_batch = next(val_ds)\n",
    "#         val_step(x_val_batch, y_val_batch, 0.0)\n",
    "\n",
    "#         # log metrics every 25 iterations\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "#         val_perf_losses.append(metrics[\"val_performance_loss\"].result())\n",
    "#         metrics[\"val_performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "#         val_disc_losses.append(metrics[\"val_discriminator_loss\"].result())\n",
    "#         metrics[\"val_discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()\n",
    "#         val_losses.append(metrics[\"val_loss\"].result())\n",
    "#         metrics[\"val_loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can validate training by making some simple plots of the loss curves. These are plots we'll make repeatedly, so we extract them into a reusable function.\n",
    "\n",
    "In this case everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(\n",
    "    losses,\n",
    "    val_losses,\n",
    "    perf_losses,\n",
    "    val_perf_losses,\n",
    "    disc_losses,\n",
    "    val_disc_losses,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare loss curves on train and validation sets.\n",
    "    \"\"\"\n",
    "    f, ax = plt.subplots(ncols=3, figsize=(16, 5))\n",
    "\n",
    "    def plot_loss_curves(ls, vls, ax, title):\n",
    "        ax.plot([i * 25 for i, _ in enumerate(ls)], ls, label=\"train\")\n",
    "        ax.plot([i * 25 for i, _ in enumerate(vls)], vls, label=\"val\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Iteration\")\n",
    "        ax.legend()\n",
    "\n",
    "    plot_loss_curves(losses, val_losses, ax[0], \"Loss\")\n",
    "    plot_loss_curves(perf_losses, val_perf_losses, ax[1], \"Performance loss\")\n",
    "    plot_loss_curves(disc_losses, val_disc_losses, ax[2], \"Discriminator loss\")\n",
    "\n",
    "\n",
    "# plot_losses(\n",
    "#     losses, val_losses, perf_losses, val_perf_losses, disc_losses, val_disc_losses\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having warmed up, we now train the model against the adversary to remove discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full training\n",
    "# for i in tqdm(range(ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "\n",
    "#     model_training_step(\n",
    "#         x_train_batch, y_train_batch, DISCRIMINATOR_LOSS_WEIGHT\n",
    "#     )\n",
    "\n",
    "#     for j in range(DISCRIMINATOR_STEPS):\n",
    "#         x_train_batch, _ = next(ds)\n",
    "#         discriminator_training_step(x_train_batch)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         x_val_batch, y_val_batch = next(val_ds)\n",
    "#         val_step(x_val_batch, y_val_batch, DISCRIMINATOR_LOSS_WEIGHT)\n",
    "\n",
    "#         # log metrics every 25 iterations\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "#         val_perf_losses.append(metrics[\"val_performance_loss\"].result())\n",
    "#         metrics[\"val_performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "#         val_disc_losses.append(metrics[\"val_discriminator_loss\"].result())\n",
    "#         metrics[\"val_discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()\n",
    "#         val_losses.append(metrics[\"val_loss\"].result())\n",
    "#         metrics[\"val_loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we plot the loss curves to check that training has roughly proceeded as follows. Notice a there's a step change when we change the weighting in the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_losses(\n",
    "#     losses, val_losses, perf_losses, val_perf_losses, disc_losses, val_disc_losses\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate some metrics on the test set. We compare to the same metrics for the baseline model. We see that both the score level and decision level measures of demographic parity are drastically reduced, and that we also see a small reduction in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test_sex.flatten() == 1\n",
    "\n",
    "# baseline metrics\n",
    "bl_test_probs = baseline_model.predict_proba(\n",
    "    test_oh.drop(columns=\"salary\").values\n",
    ")[:, 1]\n",
    "bl_test_pred = bl_test_probs >= 0.5\n",
    "\n",
    "bl_test_acc = accuracy(bl_test_probs, test_salary)\n",
    "bl_test_did = disparate_impact_d(bl_test_probs, test_sex.flatten())\n",
    "bl_test_dip = disparate_impact_p(bl_test_probs, test_sex.flatten())\n",
    "\n",
    "# new model metrics\n",
    "test_logits, _ = dp_pipeline((test_features, test_sex))\n",
    "test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "test_pred = test_probs >= 0.5\n",
    "\n",
    "test_acc = accuracy(test_probs, test_salary)\n",
    "test_did = disparate_impact_d(test_probs, test_sex.flatten())\n",
    "test_dip = disparate_impact_p(test_probs, test_sex.flatten())\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline disparate impact (dist.): {bl_test_did:.3f}\")\n",
    "print(f\"Disparate impact (dist.): {test_did:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline disparate impact (prob.): {bl_test_dip:.3f}\")\n",
    "print(f\"Disparate impact (prob.): {test_dip:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further visualise the improvement with a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_box = group_box_plots(\n",
    "    np.concatenate([bl_test_probs, test_probs]),\n",
    "    np.concatenate([np.zeros_like(bl_test_probs), np.ones_like(test_probs)]),\n",
    "    np.tile(test.sex.map(lambda x: \"Male\" if x else \"Female\"), 2),\n",
    "    group_names=[\"Baseline\", \"Adversarial model\"],\n",
    ")\n",
    "dp_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(dp_box, \"adversarial-dp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean female and male scores are relatively close, and we have preserved accuracy pretty well also.\n",
    "\n",
    "## Conditional demographic parity.\n",
    "\n",
    "We'll now repeat the process for conditional demographic parity, where we use `hours_per_week` as a legitimate risk factor when predicting someone's salary. As you'll see, we don't need to make many modifications to the code, the principal difference being that the discriminator gets direct access to `hours_per_week`. This means that the model gets no benefit from removing information about `hours_per_week` from its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=MODEL_ACTIVATION)\n",
    "        for units in MODEL_HIDDEN_UNITS\n",
    "    ],\n",
    "    name=\"model\",\n",
    ")\n",
    "# no activation in last layer, model outputs logits not probabilities.\n",
    "cdp_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "cdp_discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=DISCRIMINATOR_ACTIVATION)\n",
    "        for units in DISCRIMINATOR_HIDDEN_UNITS\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "# also no activation function here.\n",
    "cdp_discriminator.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline to manage training. This pipeline contains the original model, and feeds the outputs of the model to the discriminator. We now also pass the legitimate risk factors to the discriminator directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.keras.Input(train_features.shape[1] - 1)\n",
    "legitimate_risk_factors = tf.keras.Input(1)\n",
    "attribute = tf.keras.Input(1)\n",
    "\n",
    "# features, protected data and legitimate risk factors all passed to model\n",
    "model_inputs = tf.keras.layers.concatenate(\n",
    "    [features, legitimate_risk_factors, attribute]\n",
    ")\n",
    "model_outputs = cdp_model(model_inputs)\n",
    "\n",
    "# discriminator receives model outputs and legitimate risk factors\n",
    "discriminator_inputs = tf.keras.layers.concatenate(\n",
    "    [model_outputs, legitimate_risk_factors]\n",
    ")\n",
    "discriminator_outputs = cdp_discriminator(model_outputs)\n",
    "\n",
    "# pipeline outputs both model and discriminator outputs\n",
    "cdp_pipeline = tf.keras.Model(\n",
    "    inputs=[features, legitimate_risk_factors, attribute],\n",
    "    outputs=[model_outputs, discriminator_outputs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We once again build Tensorflow datasets from the data. These will handle batching and shuffling of the data during training. Note that now we separate hours per week from the rest of the data so that we can pass it to the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cdp_features = train_oh.drop(\n",
    "    columns=[\"sex\", \"salary\", \"hours_per_week\"]\n",
    ").values\n",
    "val_cdp_features = val_oh.drop(\n",
    "    columns=[\"sex\", \"salary\", \"hours_per_week\"]\n",
    ").values\n",
    "test_cdp_features = test_oh.drop(\n",
    "    columns=[\"sex\", \"salary\", \"hours_per_week\"]\n",
    ").values\n",
    "\n",
    "train_hpw = train_oh[[\"hours_per_week\"]].values\n",
    "val_hpw = val_oh[[\"hours_per_week\"]].values\n",
    "test_hpw = test_oh[[\"hours_per_week\"]].values\n",
    "\n",
    "train_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((train_cdp_features, train_sex, train_hpw), train_salary)\n",
    "    )\n",
    "    .shuffle(buffer_size=BATCH_SIZE * 16, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((val_cdp_features, val_sex, val_hpw), val_salary)\n",
    "    )\n",
    "    .batch(val_features.shape[0])\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((test_cdp_features, test_sex, test_hpw), test_salary)\n",
    "    )\n",
    "    .batch(test_features.shape[0])\n",
    "    .repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training steps. These are as before, but we use the `cdp_pipeline` instead of the `dp_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    model_training_step,\n",
    "    discriminator_training_step,\n",
    "    val_step,\n",
    "    metrics,\n",
    ") = make_training_steps(\n",
    "    cdp_pipeline, MODEL_LEARNING_RATE, DISCRIMINATOR_LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model typicall takes a couple of minutes, so we load a trained model from disk here, but all the code used to train the model we're loading is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_pipeline = tf.keras.models.load_model(\n",
    "    artifacts_dir / \"models\" / \"finance\" / \"adversarial-cdp.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to train the model. We'll manually track the losses with a list since our setup is not too complicated, but we could also log metrics to [TensorBoard](https://www.tensorflow.org/tensorboard/) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = iter(train_data)\n",
    "# val_ds = iter(val_data)\n",
    "\n",
    "# perf_losses = []\n",
    "# disc_losses = []\n",
    "# losses = []\n",
    "\n",
    "# val_perf_losses = []\n",
    "# val_disc_losses = []\n",
    "# val_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by warming up the model without a fairness constraint to help optimisation later. Since the fairness and performance objectives are in tension, it's helpful to first roughly optimise for performance before brining in the fairness constraint.\n",
    "\n",
    "To train we'll simply loop over the training data and apply the model training step with the discriminator weight set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(WARMUP_ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "#     model_training_step(x_train_batch, y_train_batch, 0.0)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         x_val_batch, y_val_batch = next(val_ds)\n",
    "#         val_step(x_val_batch, y_val_batch, 0.0)\n",
    "\n",
    "#         # log metrics every 25 iterations\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "#         val_perf_losses.append(metrics[\"val_performance_loss\"].result())\n",
    "#         metrics[\"val_performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "#         val_disc_losses.append(metrics[\"val_discriminator_loss\"].result())\n",
    "#         metrics[\"val_discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()\n",
    "#         val_losses.append(metrics[\"val_loss\"].result())\n",
    "#         metrics[\"val_loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can validate training by making some simple plots of the loss curves. In this case everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_losses(\n",
    "#     losses, val_losses, perf_losses, val_perf_losses, disc_losses, val_disc_losses\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having warmed up, we now train the model against the adversary to remove discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full training\n",
    "# for i in tqdm(range(ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "\n",
    "#     model_training_step(\n",
    "#         x_train_batch, y_train_batch, DISCRIMINATOR_LOSS_WEIGHT\n",
    "#     )\n",
    "\n",
    "#     for j in range(DISCRIMINATOR_STEPS):\n",
    "#         x_train_batch, _ = next(ds)\n",
    "#         discriminator_training_step(x_train_batch)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         x_val_batch, y_val_batch = next(val_ds)\n",
    "#         val_step(x_val_batch, y_val_batch, DISCRIMINATOR_LOSS_WEIGHT)\n",
    "\n",
    "#         # log metrics every 25 iterations\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "#         val_perf_losses.append(metrics[\"val_performance_loss\"].result())\n",
    "#         metrics[\"val_performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "#         val_disc_losses.append(metrics[\"val_discriminator_loss\"].result())\n",
    "#         metrics[\"val_discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()\n",
    "#         val_losses.append(metrics[\"val_loss\"].result())\n",
    "#         metrics[\"val_loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we plot the loss curves to check that training has roughly proceeded as follows. Notice a there's a step change when we change the weighting in the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_losses(\n",
    "#     losses, val_losses, perf_losses, val_perf_losses, disc_losses, val_disc_losses\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute demographic parity conditioned on binned values of `hours_per_week` and compare against the baseline. Once again we see a major improvement but a slight drop in accuracy as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test_sex.flatten() == 1\n",
    "test_binned_hpw = test.hours_per_week.map(bin_hours_per_week).values\n",
    "\n",
    "# baseline metrics\n",
    "bl_test_probs = baseline_model.predict_proba(\n",
    "    test_oh.drop(columns=\"salary\").values\n",
    ")[:, 1]\n",
    "bl_test_pred = bl_test_probs >= 0.5\n",
    "\n",
    "bl_test_acc = accuracy(bl_test_probs, test_salary)\n",
    "bl_test_did = 0\n",
    "bl_test_dip = 0\n",
    "\n",
    "for val in set(test_binned_hpw):\n",
    "    bin_mask = test_binned_hpw == val\n",
    "    bl_test_did += disparate_impact_d(\n",
    "        bl_test_probs[bin_mask], test_sex[bin_mask].flatten()\n",
    "    )\n",
    "    bl_test_dip += disparate_impact_p(\n",
    "        bl_test_probs[bin_mask], test_sex[bin_mask].flatten()\n",
    "    )\n",
    "\n",
    "bl_test_did /= 4\n",
    "bl_test_dip /= 4\n",
    "\n",
    "# new model metrics\n",
    "test_logits, _ = cdp_pipeline((test_cdp_features, test_sex, test_hpw))\n",
    "test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "test_pred = test_probs >= 0.5\n",
    "\n",
    "test_acc = accuracy(test_probs, test_salary)\n",
    "test_did = 0\n",
    "test_dip = 0\n",
    "\n",
    "for val in set(test_binned_hpw):\n",
    "    bin_mask = test_binned_hpw == val\n",
    "    test_did += disparate_impact_d(\n",
    "        test_probs[bin_mask], test_sex[bin_mask].flatten()\n",
    "    )\n",
    "    test_dip += disparate_impact_p(\n",
    "        test_probs[bin_mask], test_sex[bin_mask].flatten()\n",
    "    )\n",
    "\n",
    "test_did /= 4\n",
    "test_dip /= 4\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline disparate impact (dist.): {bl_test_did:.3f}\")\n",
    "print(f\"Disparate impact (dist.): {test_did:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline disparate impact (prob.): {bl_test_dip:.3f}\")\n",
    "print(f\"Disparate impact (prob.): {test_dip:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise the improvement with a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_cdp_box = group_box_plots(\n",
    "    bl_test_probs,\n",
    "    test.hours_per_week.map(bin_hours_per_week),\n",
    "    test_oh.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    group_names=[\"<30hrs\", \"30-40hrs\", \"40-50hrs\", \">50hrs\"],\n",
    ")\n",
    "bl_cdp_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_box = group_box_plots(\n",
    "    test_probs,\n",
    "    test.hours_per_week.map(bin_hours_per_week),\n",
    "    test_oh.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    group_names=[\"<30hrs\", \"30-40hrs\", \"40-50hrs\", \">50hrs\"],\n",
    ")\n",
    "cdp_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(bl_cdp_box, \"bl-adversarial-cdp.json\")\n",
    "export_plot(cdp_box, \"adversarial-cdp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal opportunity\n",
    "\n",
    "Finally we repeat the process for conditional demographic parity. Once again the code is similar, all that changes is that we now pass the labels to the discriminator. This means that hte model gets no benegit from removing from its outputs information about the protected attribute that is contained in the labels.\n",
    "\n",
    "On this dataset equal opportunity seems harder to achieve, so we use a slightly more complex model, and we increase the discriminator weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 2048\n",
    "DISCRIMINATOR_STEPS = 10\n",
    "\n",
    "MODEL_HIDDEN_UNITS = [50, 50, 50]\n",
    "\n",
    "DISCRIMINATOR_HIDDEN_UNITS = [50, 50, 50]\n",
    "DISCRIMINATOR_LOSS_WEIGHT = 0.975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=MODEL_ACTIVATION)\n",
    "        for units in MODEL_HIDDEN_UNITS\n",
    "    ],\n",
    "    name=\"model\",\n",
    ")\n",
    "eo_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "eo_discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=DISCRIMINATOR_ACTIVATION)\n",
    "        for units in DISCRIMINATOR_HIDDEN_UNITS\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "eo_discriminator.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline to manage training. This pipeline contains the original model, and feeds the outputs of the model to the discriminator. We now also pass the labels to the discriminator directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.keras.Input(train_features.shape[1])\n",
    "salary = tf.keras.Input(1)\n",
    "attribute = tf.keras.Input(1)\n",
    "\n",
    "# features and protected attribute passed to model, NOT labels!\n",
    "model_inputs = tf.keras.layers.concatenate([features, attribute])\n",
    "model_outputs = eo_model(model_inputs)\n",
    "\n",
    "# model outputs and labels passed to discriminator\n",
    "discriminator_inputs = tf.keras.layers.concatenate([model_outputs, salary])\n",
    "discriminator_outputs = eo_discriminator(model_outputs)\n",
    "\n",
    "eo_pipeline = tf.keras.Model(\n",
    "    inputs=[features, attribute, salary],\n",
    "    outputs=[model_outputs, discriminator_outputs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We once again build Tensorflow datasets from the data. These will handle batching and shuffling of the data during training. Note that now we pass labels in as part of the data so that we can feed it to the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            (train_features, train_sex, train_salary.reshape(-1, 1)),\n",
    "            train_salary,\n",
    "        )\n",
    "    )\n",
    "    .shuffle(buffer_size=BATCH_SIZE * 16, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((val_features, val_sex, val_salary.reshape(-1, 1)), val_salary)\n",
    "    )\n",
    "    .batch(val_features.shape[0])\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((test_features, test_sex, test_salary.reshape(-1, 1)), test_salary)\n",
    "    )\n",
    "    .batch(test_features.shape[0])\n",
    "    .repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training steps. These are as before, but we use the `eo_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    model_training_step,\n",
    "    discriminator_training_step,\n",
    "    val_step,\n",
    "    metrics,\n",
    ") = make_training_steps(\n",
    "    eo_pipeline, MODEL_LEARNING_RATE, DISCRIMINATOR_LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model typically takes a couple of minutes, so we load a trained model from disk here, but all the code used to train the model we're loading is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_pipeline = tf.keras.models.load_model(\n",
    "    artifacts_dir / \"models\" / \"finance\" / \"adversarial-eo.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to train the model. We'll manually track the losses with a list since our setup is not too complicated, but we could also log metrics to [TensorBoard](https://www.tensorflow.org/tensorboard/) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = iter(train_data)\n",
    "# val_ds = iter(val_data)\n",
    "\n",
    "# perf_losses = []\n",
    "# disc_losses = []\n",
    "# losses = []\n",
    "\n",
    "# val_perf_losses = []\n",
    "# val_disc_losses = []\n",
    "# val_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by warming up the model without a fairness constraint to help optimisation later. Since the fairness and performance objectives are in tension, it's helpful to first roughly optimise for performance before brining in the fairness constraint.\n",
    "\n",
    "To train we'll simply loop over the training data and apply the model training step with the discriminator weight set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(WARMUP_ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "#     model_training_step(x_train_batch, y_train_batch, 0.0)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         x_val_batch, y_val_batch = next(val_ds)\n",
    "#         val_step(x_val_batch, y_val_batch, 0.0)\n",
    "\n",
    "#         # log metrics every 25 iterations\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "#         val_perf_losses.append(metrics[\"val_performance_loss\"].result())\n",
    "#         metrics[\"val_performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "#         val_disc_losses.append(metrics[\"val_discriminator_loss\"].result())\n",
    "#         metrics[\"val_discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()\n",
    "#         val_losses.append(metrics[\"val_loss\"].result())\n",
    "#         metrics[\"val_loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can validate training by making some simple plots of the loss curves. In this case everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_losses(\n",
    "#     losses, val_losses, perf_losses, val_perf_losses, disc_losses, val_disc_losses\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having warmed up, we now train the model against the adversary to remove discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full training\n",
    "# for i in tqdm(range(ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "\n",
    "#     model_training_step(\n",
    "#         x_train_batch, y_train_batch, DISCRIMINATOR_LOSS_WEIGHT\n",
    "#     )\n",
    "\n",
    "#     for j in range(DISCRIMINATOR_STEPS):\n",
    "#         x_train_batch, _ = next(ds)\n",
    "#         discriminator_training_step(x_train_batch)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         x_val_batch, y_val_batch = next(val_ds)\n",
    "#         val_step(x_val_batch, y_val_batch, DISCRIMINATOR_LOSS_WEIGHT)\n",
    "\n",
    "#         # log metrics every 25 iterations\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "#         val_perf_losses.append(metrics[\"val_performance_loss\"].result())\n",
    "#         metrics[\"val_performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "#         val_disc_losses.append(metrics[\"val_discriminator_loss\"].result())\n",
    "#         metrics[\"val_discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()\n",
    "#         val_losses.append(metrics[\"val_loss\"].result())\n",
    "#         metrics[\"val_loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again plot the loss curves. In this case, we found that there was quite a bit of instability compared to the other definitions of fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_losses(\n",
    "#     losses, val_losses, perf_losses, val_perf_losses, disc_losses, val_disc_losses\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing metrics to the baseline, not much has changed. The accuracy stayed roughly the same. The baseline actually performed slightly better in one metric and worse in the other. Actually optimising for equalised odds is going to take more effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline metrics\n",
    "bl_test_probs = baseline_model.predict_proba(\n",
    "    test_oh.drop(columns=\"salary\").values\n",
    ")[:, 1]\n",
    "bl_test_pred = bl_test_probs >= 0.5\n",
    "\n",
    "bl_test_acc = accuracy(bl_test_probs, test_salary)\n",
    "bl_test_eod = equalised_odds_d(bl_test_probs, test_sex.flatten(), test_salary)\n",
    "bl_test_eop = equalised_odds_p(bl_test_probs, test_sex.flatten(), test_salary)\n",
    "\n",
    "# new model metrics\n",
    "test_logits, _ = eo_pipeline((test_features, test_sex, test_salary))\n",
    "test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "test_pred = test_probs >= 0.5\n",
    "\n",
    "test_acc = accuracy(test_probs, test_salary)\n",
    "test_eod = equalised_odds_d(test_probs, test_sex.flatten(), test_salary)\n",
    "test_eop = equalised_odds_p(test_probs, test_sex.flatten(), test_salary)\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline equalised odds (dist.): {bl_test_eod:.3f}\")\n",
    "print(f\"Equalised odds (dist.): {test_eod:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline equalised odds (prob.): {bl_test_eop:.3f}\")\n",
    "print(f\"Equalised odds (prob.): {test_eop:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_eo_box = group_box_plots(\n",
    "    bl_test_probs,\n",
    "    test.salary,\n",
    "    test_oh.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    group_names=[\"<= $50k\", \"> $50k\"],\n",
    ")\n",
    "bl_eo_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_box = group_box_plots(\n",
    "    test_probs,\n",
    "    test.salary,\n",
    "    test_oh.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    group_names=[\"<= $50k\", \"> $50k\"],\n",
    ")\n",
    "eo_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(bl_eo_box, \"bl-adversarial-eo.json\")\n",
    "export_plot(eo_box, \"adversarial-eo.json\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
