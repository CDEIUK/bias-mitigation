{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial debiasing - Adult data\n",
    "\n",
    "This notebook contains a simple implementations of the algorithm presented in [Mitigating Unwated Biases with Adversarial Learning](https://dl.acm.org/doi/10.1145/3278721.3278779) by Zhang et al.\n",
    "\n",
    "We train a model in tandem with an adversary that tries to predict sensitive data from the model outputs. By training the model not only to perform well, but also to fool the adversary we achieve fairness. By varying what we allow the adversary to see, we can achieve different notions of fairness with an otherwise very similar setup. In this notebook we demonstrate demographic parity, conditional demographic parity and equalised odds.\n",
    "\n",
    "For simplicity, we'll focus mitigating bias with resepct to `sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from helpers.finance import bin_hours_per_week, preprocess\n",
    "from helpers.plot import group_box_plots, group_roc_curves\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from helpers import export_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(arr):\n",
    "    return 1 / (1 + np.exp(-arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set some global hyperparameters for easy reference. Feel free to experiment with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "ITERATIONS = 5000\n",
    "WARMUP_ITERATIONS = 2000\n",
    "# number of discriminator training steps per model training step\n",
    "DISCRIMINATOR_STEPS = 5\n",
    "\n",
    "MODEL_HIDDEN_UNITS = [50, 50]\n",
    "MODEL_ACTIVATION = \"relu\"\n",
    "MODEL_LEARNING_RATE = 1e-4\n",
    "\n",
    "DISCRIMINATOR_HIDDEN_UNITS = [50, 50]\n",
    "DISCRIMINATOR_ACTIVATION = \"relu\"\n",
    "DISCRIMINATOR_LEARNING_RATE = 1e-2\n",
    "DISCRIMINATOR_LOSS_WEIGHT = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of artifacts (model and data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# override data_dir in source notebook\n",
    "# this is stripped out for the hosted notebooks\n",
    "artifacts_dir = Path(\"../../../../artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"adult\"\n",
    "preprocess(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow expects float32 data, so we cast all columns on load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh = pd.read_csv(data_dir / \"processed\" / \"train-one-hot.csv\").astype(\n",
    "    np.float32\n",
    ")\n",
    "val_oh = pd.read_csv(data_dir / \"processed\" / \"val-one-hot.csv\").astype(\n",
    "    np.float32\n",
    ")\n",
    "test_oh = pd.read_csv(data_dir / \"processed\" / \"test-one-hot.csv\").astype(\n",
    "    np.float32\n",
    ")\n",
    "\n",
    "# unscaled data for making plots\n",
    "train = pd.read_csv(data_dir / \"processed\" / \"train.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create NumPy arrays of relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_oh.drop(columns=[\"sex\", \"salary\"]).values\n",
    "train_sex = train_oh[[\"sex\"]].values\n",
    "train_salary = train_oh[\"salary\"].values\n",
    "\n",
    "val_features = val_oh.drop(columns=[\"sex\", \"salary\"]).values\n",
    "val_sex = val_oh[[\"sex\"]].values\n",
    "val_salary = val_oh[\"salary\"].values\n",
    "\n",
    "test_features = test_oh.drop(columns=[\"sex\", \"salary\"]).values\n",
    "test_sex = test_oh[[\"sex\"]].values\n",
    "test_salary = test_oh[\"salary\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic parity.\n",
    "\n",
    "Build a model and an adversary. We use simple feed-forward networks in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=MODEL_ACTIVATION)\n",
    "        for units in MODEL_HIDDEN_UNITS\n",
    "    ],\n",
    "    name=\"model\",\n",
    ")\n",
    "# no activation in last layer, model outputs logits not probabilities.\n",
    "dp_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "dp_discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=DISCRIMINATOR_ACTIVATION)\n",
    "        for units in DISCRIMINATOR_HIDDEN_UNITS\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "# also no activation function here.\n",
    "dp_discriminator.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline to manage training. This pipeline contains the original model, and feeds the outputs of the model to the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.keras.Input(train_features.shape[1])\n",
    "attribute = tf.keras.Input(1)\n",
    "\n",
    "# concatenate features and protected data to pass to model\n",
    "model_inputs = tf.keras.layers.concatenate([features, attribute])\n",
    "model_outputs = dp_model(model_inputs)\n",
    "\n",
    "# pass model outputs to discriminator\n",
    "discriminator_outputs = dp_discriminator(model_outputs)\n",
    "\n",
    "# pipeline outputs both model and discriminator outputs\n",
    "dp_pipeline = tf.keras.Model(\n",
    "    inputs=[features, attribute],\n",
    "    outputs=[model_outputs, discriminator_outputs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build Tensorflow datasets from the data. These will handle batching and shuffling of the data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((train_features, train_sex), train_salary)\n",
    "    )\n",
    "    .shuffle(buffer_size=BATCH_SIZE * 16, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(((val_features, val_sex), val_salary))\n",
    "    .batch(val_features.shape[0])\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((test_features, test_sex), test_salary)\n",
    "    )\n",
    "    .batch(test_features.shape[0])\n",
    "    .repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate optimisers for the model and discriminator\n",
    "model_optim = tf.optimizers.Adam(MODEL_LEARNING_RATE)\n",
    "discriminator_optim = tf.optimizers.Adam(DISCRIMINATOR_LEARNING_RATE)\n",
    "\n",
    "# use binary cross entropy for losses, note from_logits=True as we\n",
    "# have not normalised the model outputs into probabilities.\n",
    "binary_cross_entropy = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# lists of variables that will be updated during training.\n",
    "dp_model_vars = dp_model.trainable_variables\n",
    "dp_discriminator_vars = dp_discriminator.trainable_variables\n",
    "\n",
    "# create a dictionary of metrics for easy tracking of losses\n",
    "metrics = {\n",
    "    \"performance_loss\": tf.metrics.Mean(\"performance-loss\", dtype=tf.float32),\n",
    "    \"discriminator_loss\": tf.metrics.Mean(\n",
    "        \"discriminator-loss\", dtype=tf.float32\n",
    "    ),\n",
    "    \"loss\": tf.metrics.Mean(\"loss\", dtype=tf.float32),\n",
    "}\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def model_training_step(x_train, y_train, discriminator_loss_weight):\n",
    "    \"\"\"\n",
    "    The weights of the model are trained by minimising.\n",
    "    \n",
    "    (1 - dlw) * model_loss - dlw * discriminator_loss\n",
    "    \n",
    "    The minus sign in front of the discriminator loss means we try to\n",
    "    maximise it, thereby removing information about the protected\n",
    "    attribute from the model outputs.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        fair_logits, discriminator_logits = dp_pipeline(x_train)\n",
    "        performance_loss = binary_cross_entropy(y_train, fair_logits)\n",
    "        discriminator_loss = binary_cross_entropy(\n",
    "            x_train[1], discriminator_logits\n",
    "        )\n",
    "        loss = (\n",
    "            (1 - discriminator_loss_weight) * performance_loss\n",
    "            - discriminator_loss_weight * discriminator_loss\n",
    "        )\n",
    "\n",
    "    metrics[\"performance_loss\"](performance_loss)\n",
    "    metrics[\"discriminator_loss\"](discriminator_loss)\n",
    "    metrics[\"loss\"](loss)\n",
    "\n",
    "    # compute gradients and pass to optimiser\n",
    "    grads = tape.gradient(loss, dp_model_vars)\n",
    "    model_optim.apply_gradients(zip(grads, dp_model_vars))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def discriminator_training_step(x_train):\n",
    "    \"\"\"\n",
    "    The weights of the discriminator are simply trained by minimising\n",
    "    the discriminator loss directly.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        _, discriminator_logits = dp_pipeline(x_train)\n",
    "        discriminator_loss = binary_cross_entropy(\n",
    "            x_train[1], discriminator_logits\n",
    "        )\n",
    "\n",
    "    grads = tape.gradient(discriminator_loss, dp_discriminator_vars)\n",
    "    discriminator_optim.apply_gradients(zip(grads, dp_discriminator_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model typically takes a couple of minutes, so we load a trained model from disk here, but all the code used to train the model we're loading is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_pipeline = tf.keras.models.load_model(\n",
    "    artifacts_dir / \"models\" / \"adversarial-dp.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to train the model. We'll manually track the losses with a list since our setup is not too complicated, but we could also log metrics to [TensorBoard](https://www.tensorflow.org/tensorboard/) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = iter(train_data)\n",
    "# val_ds = iter(val_data)\n",
    "\n",
    "# perf_losses = []\n",
    "# disc_losses = []\n",
    "# losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by warming up the model without a fairness constraint to help optimisation later. Since the fairness and performance objectives are in tension, it's helpful to first roughly optimise for performance before brining in the fairness constraint.\n",
    "\n",
    "To train we'll simply loop over the training data and apply the model training step with the discriminator weight set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(WARMUP_ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "#     model_training_step(x_train_batch, y_train_batch, 0.0)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         # log metrics every 25 iterations\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can validate training by making some simple plots of the loss curves. In this case everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(ncols=3, figsize=(16, 5))\n",
    "\n",
    "# ax[0].plot([i * 25 for i, _ in enumerate(losses)], losses)\n",
    "# ax[0].set_title(\"Loss\")\n",
    "\n",
    "# ax[1].plot([i * 25 for i, _ in enumerate(perf_losses)], perf_losses)\n",
    "# ax[1].set_title(\"Performance loss\")\n",
    "\n",
    "# ax[2].plot([i * 25 for i, _ in enumerate(disc_losses)], disc_losses)\n",
    "# ax[2].set_title(\"Discriminator loss\")\n",
    "\n",
    "# for a in ax:\n",
    "#     a.set_xlabel(\"Iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at some simple performance metrics. Without too much effort to optimise, we get an accuracy of about 85%, but a big disparity between male and female scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_logits, _ = dp_pipeline((test_features, test_sex))\n",
    "# test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "# test_pred = test_probs >= 0.5\n",
    "\n",
    "# mask = test_sex.flatten() == 1\n",
    "\n",
    "# print(f\"Accuracy: {(test_pred == test_salary).mean():.3f}\")\n",
    "\n",
    "# print(f\"Female accuracy: {(test_pred == test_salary)[~mask].mean():.3f}\")\n",
    "# print(f\"Male accuracy: {(test_pred == test_salary)[mask].mean():.3f}\")\n",
    "\n",
    "# print(f\"Mean female score: {test_probs[~mask].mean():.3f}\")\n",
    "# print(f\"Mean male score: {test_probs[mask].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having warmed up, we now train the model against the adversary to remove discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full training\n",
    "# for i in tqdm(range(ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "\n",
    "#     model_training_step(\n",
    "#         x_train_batch, y_train_batch, DISCRIMINATOR_LOSS_WEIGHT\n",
    "#     )\n",
    "\n",
    "#     for j in range(DISCRIMINATOR_STEPS):\n",
    "#         x_train_batch, _ = next(ds)\n",
    "#         discriminator_training_step(x_train_batch)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we plot the loss curves to check that training has roughly proceeded as follows. Notice a there's a step change when we change the weighting in the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(ncols=3, figsize=(16, 5))\n",
    "\n",
    "# ax[0].plot([i * 25 for i, _ in enumerate(losses)], losses)\n",
    "# ax[0].set_title(\"Loss\")\n",
    "\n",
    "# ax[1].plot([i * 25 for i, _ in enumerate(perf_losses)], perf_losses)\n",
    "# ax[1].set_title(\"Performance loss\")\n",
    "\n",
    "# ax[2].plot([i * 25 for i, _ in enumerate(disc_losses)], disc_losses)\n",
    "# ax[2].set_title(\"Discriminator loss\")\n",
    "\n",
    "# for a in ax:\n",
    "#     a.set_xlabel(\"Iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate some metrics on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logits, _ = dp_pipeline((test_features, test_sex))\n",
    "test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "test_pred = test_probs >= 0.5\n",
    "\n",
    "mask = test_sex.flatten() == 1\n",
    "\n",
    "print(f\"Accuracy: {(test_pred == test_salary).mean():.3f}\")\n",
    "\n",
    "print(f\"Female accuracy: {(test_pred == test_salary)[~mask].mean():.3f}\")\n",
    "print(f\"Male accuracy: {(test_pred == test_salary)[mask].mean():.3f}\")\n",
    "\n",
    "print(f\"Mean female score: {test_probs[~mask].mean():.3f}\")\n",
    "print(f\"Mean male score: {test_probs[mask].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_box = group_box_plots(\n",
    "    test_probs,\n",
    "    np.zeros_like(test_probs),\n",
    "    test.sex.map(lambda x: \"Male\" if x else \"Female\"),\n",
    "    group_names=[\"\"],\n",
    ")\n",
    "dp_box.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(dp_box, \"adversarial-dp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean female and male scores are relatively close, and we have preserved accuracy pretty well also.\n",
    "\n",
    "## Conditional demographic parity.\n",
    "\n",
    "We'll now repeat the process for conditional demographic parity, where we use `hours_per_week` as a legitimate risk factor when predicting someone's salary. As you'll see, we don't need to make many modifications to the code, the principal difference being that the discriminator gets direct access to `hours_per_week`. This means that the model gets no benefit from removing information about `hours_per_week` from its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=MODEL_ACTIVATION)\n",
    "        for units in MODEL_HIDDEN_UNITS\n",
    "    ]\n",
    ")\n",
    "# no activation in last layer, model outputs logits not probabilities.\n",
    "cdp_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "cdp_discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=DISCRIMINATOR_ACTIVATION)\n",
    "        for units in DISCRIMINATOR_HIDDEN_UNITS\n",
    "    ]\n",
    ")\n",
    "# also no activation function here.\n",
    "cdp_discriminator.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline to manage training. This pipeline contains the original model, and feeds the outputs of the model to the discriminator. We now also pass the legitimate risk factors to the discriminator directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.keras.Input(train_features.shape[1] - 1)\n",
    "legitimate_risk_factors = tf.keras.Input(1)\n",
    "attribute = tf.keras.Input(1)\n",
    "\n",
    "# features, protected data and legitimate risk factors all passed to model\n",
    "model_inputs = tf.keras.layers.concatenate(\n",
    "    [features, legitimate_risk_factors, attribute]\n",
    ")\n",
    "model_outputs = cdp_model(model_inputs)\n",
    "\n",
    "# discriminator receives model outputs and legitimate risk factors\n",
    "discriminator_inputs = tf.keras.layers.concatenate(\n",
    "    [model_outputs, legitimate_risk_factors]\n",
    ")\n",
    "discriminator_outputs = cdp_discriminator(model_outputs)\n",
    "\n",
    "# pipeline outputs both model and discriminator outputs\n",
    "cdp_pipeline = tf.keras.Model(\n",
    "    inputs=[features, legitimate_risk_factors, attribute],\n",
    "    outputs=[model_outputs, discriminator_outputs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We once again build Tensorflow datasets from the data. These will handle batching and shuffling of the data during training. Note that now we separate hours per week from the rest of the data so that we can pass it to the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cdp_features = train_oh.drop(\n",
    "    columns=[\"sex\", \"salary\", \"hours_per_week\"]\n",
    ").values\n",
    "val_cdp_features = val_oh.drop(\n",
    "    columns=[\"sex\", \"salary\", \"hours_per_week\"]\n",
    ").values\n",
    "test_cdp_features = test_oh.drop(\n",
    "    columns=[\"sex\", \"salary\", \"hours_per_week\"]\n",
    ").values\n",
    "\n",
    "train_hpw = train_oh[[\"hours_per_week\"]].values\n",
    "val_hpw = val_oh[[\"hours_per_week\"]].values\n",
    "test_hpw = test_oh[[\"hours_per_week\"]].values\n",
    "\n",
    "train_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((train_cdp_features, train_sex, train_hpw), train_salary)\n",
    "    )\n",
    "    .shuffle(buffer_size=BATCH_SIZE * 16, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((val_features, val_sex, val_hpw), val_salary)\n",
    "    )\n",
    "    .batch(val_features.shape[0])\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((test_features, test_sex, test_hpw), test_salary)\n",
    "    )\n",
    "    .batch(test_features.shape[0])\n",
    "    .repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training steps. These are as before, but we use the `cdp_pipeline` instead of the `dp_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate optimisers for the model and discriminator\n",
    "model_optim = tf.optimizers.Adam(MODEL_LEARNING_RATE)\n",
    "discriminator_optim = tf.optimizers.Adam(DISCRIMINATOR_LEARNING_RATE)\n",
    "\n",
    "# use binary cross entropy for losses, note from_logits=True as we\n",
    "# have not normalised the model outputs into probabilities.\n",
    "binary_cross_entropy = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# lists of variables that will be updated during training.\n",
    "cdp_model_vars = cdp_model.trainable_variables\n",
    "cdp_discriminator_vars = cdp_discriminator.trainable_variables\n",
    "\n",
    "# create a dictionary of metrics for easy tracking of losses\n",
    "metrics = {\n",
    "    \"performance_loss\": tf.metrics.Mean(\"performance-loss\", dtype=tf.float32),\n",
    "    \"discriminator_loss\": tf.metrics.Mean(\n",
    "        \"discriminator-loss\", dtype=tf.float32\n",
    "    ),\n",
    "    \"loss\": tf.metrics.Mean(\"loss\", dtype=tf.float32),\n",
    "}\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def model_training_step(x_train, y_train, discriminator_loss_weight):\n",
    "    \"\"\"\n",
    "    The weights of the model are trained by minimising.\n",
    "    \n",
    "    (1 - dlw) * model_loss - dlw * discriminator_loss\n",
    "    \n",
    "    The minus sign in front of the discriminator loss means we try to\n",
    "    maximise it, thereby removing information about the protected\n",
    "    attribute from the model outputs.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        fair_logits, discriminator_logits = cdp_pipeline(x_train)\n",
    "        performance_loss = binary_cross_entropy(y_train, fair_logits)\n",
    "        discriminator_loss = binary_cross_entropy(\n",
    "            x_train[1], discriminator_logits\n",
    "        )\n",
    "        loss = (\n",
    "            (1 - discriminator_loss_weight) * performance_loss\n",
    "            - discriminator_loss_weight * discriminator_loss\n",
    "        )\n",
    "\n",
    "    metrics[\"performance_loss\"](performance_loss)\n",
    "    metrics[\"discriminator_loss\"](discriminator_loss)\n",
    "    metrics[\"loss\"](loss)\n",
    "\n",
    "    grads = tape.gradient(loss, cdp_model_vars)\n",
    "    model_optim.apply_gradients(zip(grads, cdp_model_vars))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def discriminator_training_step(x_train):\n",
    "    \"\"\"\n",
    "    The weights of the discriminator are simply trained by minimising\n",
    "    the discriminator loss directly.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        _, discriminator_logits = cdp_pipeline(x_train)\n",
    "        discriminator_loss = binary_cross_entropy(\n",
    "            x_train[1], discriminator_logits\n",
    "        )\n",
    "\n",
    "    grads = tape.gradient(discriminator_loss, cdp_discriminator_vars)\n",
    "    discriminator_optim.apply_gradients(zip(grads, cdp_discriminator_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model typicall takes a couple of minutes, so we load a trained model from disk here, but all the code used to train the model we're loading is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_pipeline = tf.keras.models.load_model(\n",
    "    artifacts_dir / \"models\" / \"adversarial-cdp.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to train the model. We'll manually track the losses with a list since our setup is not too complicated, but we could also log metrics to [TensorBoard](https://www.tensorflow.org/tensorboard/) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = iter(train_data)\n",
    "# val_ds = iter(val_data)\n",
    "\n",
    "# perf_losses = []\n",
    "# disc_losses = []\n",
    "# losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by warming up the model without a fairness constraint to help optimisation later. Since the fairness and performance objectives are in tension, it's helpful to first roughly optimise for performance before brining in the fairness constraint.\n",
    "\n",
    "To train we'll simply loop over the training data and apply the model training step with the discriminator weight set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(WARMUP_ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "#     model_training_step(x_train_batch, y_train_batch, 0.0)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can validate training by making some simple plots of the loss curves. In this case everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(ncols=3, figsize=(16, 5))\n",
    "\n",
    "# ax[0].plot([i * 25 for i, _ in enumerate(losses)], losses)\n",
    "# ax[0].set_title(\"Loss\")\n",
    "\n",
    "# ax[1].plot([i * 25 for i, _ in enumerate(perf_losses)], perf_losses)\n",
    "# ax[1].set_title(\"Performance loss\")\n",
    "\n",
    "# ax[2].plot([i * 25 for i, _ in enumerate(disc_losses)], disc_losses)\n",
    "# ax[2].set_title(\"Discriminator loss\")\n",
    "\n",
    "# for a in ax:\n",
    "#     a.set_xlabel(\"Iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the scores of this original model binned by hours per week to see whether the model achieves conditional demographic parity. In this case it appears not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_logits, _ = cdp_pipeline((test_cdp_features, test_sex, test_hpw))\n",
    "# test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "# test_pred = test_probs >= 0.5\n",
    "\n",
    "# group_box_plots(\n",
    "#     test_probs,\n",
    "#     test.hours_per_week.map(bin_hours_per_week),\n",
    "#     test_oh.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "#     group_names=[\"<30hrs\", \"30-40hrs\", \"40-50hrs\", \">50hrs\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having warmed up, we now train the model against the adversary to remove discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full training\n",
    "# for i in tqdm(range(ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "\n",
    "#     model_training_step(\n",
    "#         x_train_batch, y_train_batch, DISCRIMINATOR_LOSS_WEIGHT\n",
    "#     )\n",
    "\n",
    "#     for j in range(DISCRIMINATOR_STEPS):\n",
    "#         x_train_batch, _ = next(ds)\n",
    "#         discriminator_training_step(x_train_batch)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we plot the loss curves to check that training has roughly proceeded as follows. Notice a there's a step change when we change the weighting in the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(ncols=3, figsize=(16, 5))\n",
    "\n",
    "# ax[0].plot([i * 25 for i, _ in enumerate(losses)], losses)\n",
    "# ax[0].set_title(\"Loss\")\n",
    "\n",
    "# ax[1].plot([i * 25 for i, _ in enumerate(perf_losses)], perf_losses)\n",
    "# ax[1].set_title(\"Performance loss\")\n",
    "\n",
    "# ax[2].plot([i * 25 for i, _ in enumerate(disc_losses)], disc_losses)\n",
    "# ax[2].set_title(\"Discriminator loss\")\n",
    "\n",
    "# for a in ax:\n",
    "#     a.set_xlabel(\"Iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can once again look at the binned scores on the test set to see the effect of our intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logits, _ = cdp_pipeline((test_cdp_features, test_sex, test_hpw))\n",
    "test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "test_pred = test_probs >= 0.5\n",
    "\n",
    "mask = test_sex.flatten() == 1\n",
    "\n",
    "print(f\"Accuracy: {(test_pred == test_salary).mean():.3f}\")\n",
    "\n",
    "print(f\"Female accuracy: {(test_pred == test_salary)[~mask].mean():.3f}\")\n",
    "print(f\"Male accuracy: {(test_pred == test_salary)[mask].mean():.3f}\")\n",
    "\n",
    "print(f\"Mean female score: {test_probs[~mask].mean():.3f}\")\n",
    "print(f\"Mean male score: {test_probs[mask].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can make the same box plot again to see that the distribution of scores in each bin is very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_box = group_box_plots(\n",
    "    test_probs,\n",
    "    test.hours_per_week.map(bin_hours_per_week),\n",
    "    test_oh.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    group_names=[\"<30hrs\", \"30-40hrs\", \"40-50hrs\", \">50hrs\"],\n",
    ")\n",
    "cdp_box.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(cdp_box, \"adversarial-cdp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal opportunity\n",
    "\n",
    "Finally we repeat the process for conditional demographic parity. Once again the code is similar, all that changes is that we now pass the labels to the discriminator. This means that hte model gets no benegit from removing from its outputs information about the protected attribute that is contained in the labels.\n",
    "\n",
    "On this dataset equal opportunity seems harder to achieve, so we use a slightly more complex model, and we increase the discriminator weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 20000\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "MODEL_HIDDEN_UNITS = [50, 50, 50]\n",
    "\n",
    "DISCRIMINATOR_HIDDEN_UNITS = [50, 50, 50]\n",
    "DISCRIMINATOR_LOSS_WEIGHT = 0.975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=MODEL_ACTIVATION)\n",
    "        for units in MODEL_HIDDEN_UNITS\n",
    "    ]\n",
    ")\n",
    "eo_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "eo_discriminator = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(units, activation=DISCRIMINATOR_ACTIVATION)\n",
    "        for units in DISCRIMINATOR_HIDDEN_UNITS\n",
    "    ]\n",
    ")\n",
    "eo_discriminator.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline to manage training. This pipeline contains the original model, and feeds the outputs of the model to the discriminator. We now also pass the labels to the discriminator directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.keras.Input(train_features.shape[1])\n",
    "salary = tf.keras.Input(1)\n",
    "attribute = tf.keras.Input(1)\n",
    "\n",
    "# features and protected attribute passed to model, NOT labels!\n",
    "model_inputs = tf.keras.layers.concatenate([features, attribute])\n",
    "model_outputs = eo_model(model_inputs)\n",
    "\n",
    "# model outputs and labels passed to discriminator\n",
    "discriminator_inputs = tf.keras.layers.concatenate([model_outputs, salary])\n",
    "discriminator_outputs = eo_discriminator(model_outputs)\n",
    "\n",
    "eo_pipeline = tf.keras.Model(\n",
    "    inputs=[features, attribute, salary],\n",
    "    outputs=[model_outputs, discriminator_outputs],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We once again build Tensorflow datasets from the data. These will handle batching and shuffling of the data during training. Note that now we pass labels in as part of the data so that we can feed it to the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            (train_features, train_sex, train_salary.reshape(-1, 1)),\n",
    "            train_salary,\n",
    "        )\n",
    "    )\n",
    "    .shuffle(buffer_size=BATCH_SIZE * 16, reshuffle_each_iteration=True)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((val_features, val_sex, val_salary.reshape(-1, 1)), val_salary)\n",
    "    )\n",
    "    .batch(val_features.shape[0])\n",
    "    .repeat()\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        ((test_features, test_sex, test_salary.reshape(-1, 1)), test_salary)\n",
    "    )\n",
    "    .batch(test_features.shape[0])\n",
    "    .repeat()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training steps. These are as before, but we use the `eo_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim = tf.optimizers.Adam(MODEL_LEARNING_RATE)\n",
    "discriminator_optim = tf.optimizers.Adam(DISCRIMINATOR_LEARNING_RATE)\n",
    "\n",
    "binary_cross_entropy = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "eo_model_vars = eo_model.trainable_variables\n",
    "eo_discriminator_vars = eo_discriminator.trainable_variables\n",
    "\n",
    "metrics = {\n",
    "    \"performance_loss\": tf.metrics.Mean(\"performance-loss\", dtype=tf.float32),\n",
    "    \"discriminator_loss\": tf.metrics.Mean(\n",
    "        \"discriminator-loss\", dtype=tf.float32\n",
    "    ),\n",
    "    \"loss\": tf.metrics.Mean(\"loss\", dtype=tf.float32),\n",
    "}\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def model_training_step(x_train, y_train, discriminator_loss_weight):\n",
    "    with tf.GradientTape() as tape:\n",
    "        fair_logits, discriminator_logits = eo_pipeline(x_train)\n",
    "        performance_loss = binary_cross_entropy(y_train, fair_logits)\n",
    "        discriminator_loss = binary_cross_entropy(\n",
    "            x_train[1], discriminator_logits\n",
    "        )\n",
    "        loss = (\n",
    "            (1 - discriminator_loss_weight) * performance_loss\n",
    "            - discriminator_loss_weight * discriminator_loss\n",
    "        )\n",
    "\n",
    "    metrics[\"performance_loss\"](performance_loss)\n",
    "    metrics[\"discriminator_loss\"](discriminator_loss)\n",
    "    metrics[\"loss\"](loss)\n",
    "\n",
    "    grads = tape.gradient(loss, eo_model_vars)\n",
    "    model_optim.apply_gradients(zip(grads, eo_model_vars))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def discriminator_training_step(x_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        _, discriminator_logits = eo_pipeline(x_train)\n",
    "        discriminator_loss = binary_cross_entropy(\n",
    "            x_train[1], discriminator_logits\n",
    "        )\n",
    "\n",
    "    grads = tape.gradient(discriminator_loss, eo_discriminator_vars)\n",
    "    discriminator_optim.apply_gradients(zip(grads, eo_discriminator_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model typically takes a couple of minutes, so we load a trained model from disk here, but all the code used to train the model we're loading is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_pipeline = tf.keras.models.load_model(\n",
    "    artifacts_dir / \"models\" / \"adversarial-eo.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to train the model. We'll manually track the losses with a list since our setup is not too complicated, but we could also log metrics to [TensorBoard](https://www.tensorflow.org/tensorboard/) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = iter(train_data)\n",
    "# val_ds = iter(val_data)\n",
    "\n",
    "# perf_losses = []\n",
    "# disc_losses = []\n",
    "# losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by warming up the model without a fairness constraint to help optimisation later. Since the fairness and performance objectives are in tension, it's helpful to first roughly optimise for performance before brining in the fairness constraint.\n",
    "\n",
    "To train we'll simply loop over the training data and apply the model training step with the discriminator weight set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(WARMUP_ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "#     model_training_step(x_train_batch, y_train_batch, 0.0)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can validate training by making some simple plots of the loss curves. In this case everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(ncols=3, figsize=(16, 5))\n",
    "\n",
    "# ax[0].plot(losses)\n",
    "# ax[0].set_title(\"Loss\")\n",
    "\n",
    "# ax[1].plot(perf_losses)\n",
    "# ax[1].set_title(\"Performance loss\")\n",
    "\n",
    "# ax[2].plot(disc_losses)\n",
    "# ax[2].set_title(\"Discriminator loss\")\n",
    "\n",
    "# for a in ax:\n",
    "#     a.set_xlabel(\"Iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the scores of this original model binned by hours per week to see whether the model achieves equalised odds. In this case it appears not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_logits, _ = eo_pipeline((test_features, test_sex, test_salary))\n",
    "# test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "# test_pred = test_probs >= 0.5\n",
    "\n",
    "# group_box_plots(\n",
    "#     test_probs,\n",
    "#     test.salary,\n",
    "#     test_oh.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "#     group_names=[\"<= $50k\", \"> $50k\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having warmed up, we now train the model against the adversary to remove discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full training\n",
    "# for i in tqdm(range(ITERATIONS)):\n",
    "#     x_train_batch, y_train_batch = next(ds)\n",
    "\n",
    "#     model_training_step(\n",
    "#         x_train_batch, y_train_batch, DISCRIMINATOR_LOSS_WEIGHT\n",
    "#     )\n",
    "\n",
    "#     for j in range(DISCRIMINATOR_STEPS):\n",
    "#         x_train_batch, _ = next(ds)\n",
    "#         discriminator_training_step(x_train_batch)\n",
    "\n",
    "#     if i % 25 == 0:\n",
    "#         perf_losses.append(metrics[\"performance_loss\"].result())\n",
    "#         metrics[\"performance_loss\"].reset_states()\n",
    "\n",
    "#         disc_losses.append(metrics[\"discriminator_loss\"].result())\n",
    "#         metrics[\"discriminator_loss\"].reset_states()\n",
    "\n",
    "#         losses.append(metrics[\"loss\"].result())\n",
    "#         metrics[\"loss\"].reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(ncols=3, figsize=(16, 5))\n",
    "\n",
    "# ax[0].plot(losses)\n",
    "# ax[0].set_title(\"Loss\")\n",
    "\n",
    "# ax[1].plot(perf_losses)\n",
    "# ax[1].set_title(\"Performance loss\")\n",
    "\n",
    "# ax[2].plot(disc_losses)\n",
    "# ax[2].set_title(\"Discriminator loss\")\n",
    "\n",
    "# for a in ax:\n",
    "#     a.set_xlabel(\"Iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logits, _ = eo_pipeline((test_features, test_sex, test_salary))\n",
    "test_probs = sigmoid(test_logits.numpy().flatten())\n",
    "test_pred = test_probs >= 0.5\n",
    "\n",
    "mask = test_sex.flatten() == 1\n",
    "\n",
    "print(f\"Accuracy: {(test_pred == test_salary).mean():.3f}\")\n",
    "\n",
    "print(f\"Female accuracy: {(test_pred == test_salary)[~mask].mean():.3f}\")\n",
    "print(f\"Male accuracy: {(test_pred == test_salary)[mask].mean():.3f}\")\n",
    "\n",
    "print(f\"Mean female score: {test_probs[~mask].mean():.3f}\")\n",
    "print(f\"Mean male score: {test_probs[mask].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_box = group_box_plots(\n",
    "    test_probs,\n",
    "    test.salary,\n",
    "    test_oh.sex.map({0: \"Female\", 1: \"Male\"}),\n",
    "    group_names=[\"<= $50k\", \"> $50k\"],\n",
    ")\n",
    "eo_box.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(eo_box, \"adversarial-eo.json\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
