{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic recruiting data\n",
    "\n",
    "This notebook constructs a synthetic recruiting data set that we will use for exploring fairness interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We suppose that a large company has historical records of people that have applied to join the company, and whether or not that candidate was subsequently employed. We will use this data to train a model to predict whether individuals should be employed or not. A discussion of whether this is appropriate and how to mitigate potential biases is contained in the app.\n",
    "\n",
    "We aim to generate data in such a way that each of the features reflects certain unfair biases, as do the actual labels themselves. Biases in the features such as the level of education attained reflect systemic biases, whereas bias in the labels reflects historical biases in the hiring practices of the company.\n",
    "\n",
    "We have settled on the following features as ones that might be relevant in an automated recruitment setting.\n",
    "\n",
    "- Was the candidate referred for this position?\n",
    "- Number of career years relevant for the job\n",
    "- Whether candidate went to a Russell Group univserity\n",
    "- Did the candidate graduate with an honours degree\n",
    "- GCSE results\n",
    "- A-levels\n",
    "- Current income\n",
    "- Sex\n",
    "- Race\n",
    "- Quality of written cv\n",
    "- Years of volunteering experience\n",
    "- Years of gaps in cv\n",
    "- Level of IT skills\n",
    "- Whether currently employed or not\n",
    "\n",
    "We start by defining some high-level parameters that will control the data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000  # number of data points to generate\n",
    "P_SEX_MALE = 0.5\n",
    "P_RACE_WHITE = 0.5\n",
    "\n",
    "P_EMPLOYED_WHITE_MALE = 0.7\n",
    "P_EMPLOYED_BLACK_MALE = 0.45\n",
    "P_EMPLOYED_WHITE_FEMALE = 0.5\n",
    "P_EMPLOYED_BLACK_FEMALE = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the data\n",
    "\n",
    "We build the data up starting with demographic features. Remaining features are sampled conditional on the demographic features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"sex_male\"] = np.random.binomial(1, P_SEX_MALE, N)\n",
    "df[\"race_white\"] = np.random.binomial(1, P_RACE_WHITE, N)\n",
    "# we won't use age in the final data, we just use it\n",
    "# to ensure other features like years of experience\n",
    "# are generated consistently\n",
    "df[\"age\"] = np.floor(np.random.poisson(70, N) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that on average individuals have spent half of the time they've been of working age accumulating relevant experience. We sample from the Poisson distribution with this mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"years_experience\"] = np.random.poisson(\n",
    "    0.4 * np.where(df.age >= 22, df.age - 22, 0)\n",
    "    + df.race_white * 0.2\n",
    "    + df.sex_male * 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary variable stating whether the applicant has been referred or not. We assume men are more likely to be referred than women, and white people are more likely to be referred than black people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"referred\"] = np.random.binomial(\n",
    "    1, 0.2 + 0.4 * df.sex_male + 0.3 * df.race_white\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model the number of GCSEs better than C grade as a binomial distribution with 10 trials. The increased probability of good grades for white students is intended to reflect systemic biases in access to education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gcse\"] = np.random.binomial(10, 0.6 + df.race_white * 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A level results are mostly determined by GCSE results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_prob = (\n",
    "    0.4  # baseline probability\n",
    "    + df.gcse / 20  # adjusted for gcse results\n",
    "    + df.race_white * 0.05  # adjustest for race\n",
    "    - df.sex_male * 0.05  # adjusted for sex\n",
    ")\n",
    "\n",
    "df[\"a_level\"] = np.random.binomial(4, a_level_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample binary variable indicating whether individual went to a Russell Group Univeristy. Influenced mainly by A-levels and GCSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def russell_group_prob(row):\n",
    "    if row.a_level == 4:\n",
    "        return 0.8\n",
    "    elif row.a_level == 3 and row.gcse >= 7:\n",
    "        return 0.4\n",
    "    return 0.1\n",
    "\n",
    "\n",
    "df[\"russell_group\"] = np.random.binomial(\n",
    "    1, df.apply(russell_group_prob, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honours degree depends both on a-levels and Russell Group attendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def honours_prob(row):\n",
    "    if row.russell_group == 1:\n",
    "        return 0.9\n",
    "    return 0.2 + 0.15 * row.a_level\n",
    "\n",
    "\n",
    "df[\"honours\"] = np.random.binomial(1, df.apply(honours_prob, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years of voluntary experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"years_volunteer\"] = np.random.poisson(0.5, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_mean(row):\n",
    "    return (\n",
    "        15000\n",
    "        + row.russell_group * 3000\n",
    "        + row.race_white * 2000\n",
    "        + np.sqrt(row.years_experience) * 5000\n",
    "    )\n",
    "\n",
    "\n",
    "def salary_std(row):\n",
    "    return 1000 + np.sqrt(row.years_experience) * 2000\n",
    "\n",
    "\n",
    "# integer divide and multiply by 250 to round to nearest 250\n",
    "df[\"income\"] = (\n",
    "    np.random.normal(\n",
    "        df.apply(salary_mean, axis=1), df.apply(salary_std, axis=1),\n",
    "    )\n",
    "    // 250\n",
    "    * 250\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT skills is a simple ordered categorical variable that depends on sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"it_skills\"] = np.random.binomial(3, 0.4 + 0.3 * df.sex_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years of holes in cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"years_gaps\"] = np.random.poisson(\n",
    "    0.2\n",
    "    * (1.0 - 0.5 * df.sex_male - 0.25 * df.race_white)\n",
    "    * df.years_experience\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality of written cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"quality_cv\"] = np.random.binomial(3, 0.6, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we use a logistic regression to create a probability that the individual was employed, then sample a label with that probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def employed_prob(row):\n",
    "    return sigmoid(\n",
    "        # implicit discrimination\n",
    "        2 * row.referred\n",
    "        + 1 * row.years_experience\n",
    "        + 0.5 * row.gcse\n",
    "        + 0.8 * row.a_level\n",
    "        + 0.1 * row.russell_group\n",
    "        + 0.1 * row.honours\n",
    "        - 0.5 * row.years_gaps\n",
    "        + 0.4 * row.quality_cv\n",
    "        + 0.4 * row.it_skills\n",
    "        # explicit discrimination\n",
    "        + 0.8 * row.race_white\n",
    "        + 0.5 * row.sex_male\n",
    "        # offset\n",
    "        - 15\n",
    "    )\n",
    "\n",
    "\n",
    "df[\"employed_yes\"] = np.random.binomial(1, df.apply(employed_prob, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop age as it's no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final data looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, val and test splits\n",
    "\n",
    "We split the data into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "# Numerical attributes\n",
    "cts_features = [\n",
    "    \"a_level\",\n",
    "    \"gcse\",\n",
    "    \"years_experience\",\n",
    "    \"years_volunteer\",\n",
    "    \"income\",\n",
    "    \"it_skills\",\n",
    "    \"years_gaps\",\n",
    "    \"quality_cv\",\n",
    "]\n",
    "\n",
    "train_df_scaled = train_df.copy()\n",
    "val_df_scaled = val_df.copy()\n",
    "test_df_scaled = test_df.copy()\n",
    "\n",
    "train_df_scaled[cts_features] = ss.fit_transform(train_df[cts_features])\n",
    "val_df_scaled[cts_features] = ss.transform(val_df[cts_features])\n",
    "test_df_scaled[cts_features] = ss.transform(test_df[cts_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary platform specific directory\n",
    "data_dir = artifacts_dir / \"data\" / \"recruiting\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generated by us is committed to the repository for reproducibility. However feel free to regenerate your own version of the data and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(data_dir / \"raw\" / \"train.csv\", index=False)\n",
    "# test_df.to_csv(data_dir / \"raw\" / \"test.csv\", index=False)\n",
    "# val_df.to_csv(data_dir / \"raw\" / \"val.csv\", index=False)\n",
    "\n",
    "# train_df_scaled.to_csv(data_dir / \"processed\" / \"train.csv\", index=False)\n",
    "# val_df_scaled.to_csv(data_dir / \"processed\" / \"val.csv\", index=False)\n",
    "# test_df_scaled.to_csv(data_dir / \"processed\" / \"test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
