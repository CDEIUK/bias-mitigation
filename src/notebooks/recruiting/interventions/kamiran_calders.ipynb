{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reweighting by Kamiran and Calders - Recruiting data\n",
    "\n",
    "This notebook contains an implementation of the pre-processing fairness intervention introduced in [Data preprocessing techniques for classification without discrimination](https://link.springer.com/article/10.1007/s10115-011-0463-8) by Kamiran and Calders (2012) as part of the IBM AIF360 fairness tool box github.com/IBM/AIF360.\n",
    "\n",
    "The intervention achieves demographic parity by attaching weights to the data so that certain types of observations are more influential during training, thereby balancing out the label distributions across different protected groups. The resulting weights can also be used to resample the data set with replacement to create a fair transformed data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.datasets import StandardDataset\n",
    "from fairlearn.metrics import demographic_parity_difference\n",
    "from helpers.metrics import accuracy\n",
    "from helpers.plot import group_box_plots\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from helpers import export_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We have committed preprocessed data to the repository for reproducibility and we load it here. Check out the preprocessing notebook for details on how this data was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# override data_dir in source notebook\n",
    "# this is stripped out for the hosted notebooks\n",
    "artifacts_dir = Path(\"../../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"recruiting\"\n",
    "\n",
    "train = pd.read_csv(data_dir / \"processed\" / \"train.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process data for our fairness intervention we need to define special dataset objects which are part of every intervention pipeline within the IBM AIF360 toolbox. These objects contain the original data as well as some useful further information, e.g., which feature is the protected attribute as well as which column corresponds to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "index = train_sds.feature_names.index(\"race_white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which binary value goes with the (un-)privileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"race_white\": 1.0}]\n",
    "unprivileged_groups = [{\"race_white\": 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train unfair model\n",
    "\n",
    "For maximum reproducibility we load the baseline model from disk, but the code used to train can be found in the baseline model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_model = joblib.load(\n",
    "    artifacts_dir / \"models\" / \"recruiting\" / \"baseline.pkl\"\n",
    ")\n",
    "\n",
    "bl_test_probs = bl_model.predict_proba(test.drop(\"employed_yes\", axis=1))[:, 1]\n",
    "bl_test_pred = bl_test_probs > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic parity\n",
    "\n",
    "We learn the data transformation due to Kamiran and Claders on the training data. The transformation attaches fair weights to data it is applied to. A fair data set can then be generated via weighted sampling. We apply the transformation to the validation set, but instead of resampling according to the resulting weights, we train a logisitc regression model using the underlying weights in the validation set. Finally, we generate predictions for the test data based on the leanrnt fair logisitic regression and analyse the outcomes for fairness and accuracy.\n",
    "\n",
    "The intervention does not require any parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "RW.fit(train_sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply intervention on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sds_transf = RW.transform(val_sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train fair model\n",
    "\n",
    "We learn a logistic regression model on the validation set incorporating the learnt fair weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fair = LogisticRegression(max_iter=10000)\n",
    "X_val = val_sds_transf.features\n",
    "y_val = val_sds_transf.labels.flatten()\n",
    "model_fair.fit(X_val, y_val, sample_weight=val_sds_transf.instance_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply fair model on test set.\n",
    "\n",
    "Note that the pre-processing intervention of the validation data happens in the model prediction since the model has been based on the weighting which was determined by the reweight transformed validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sds_pred = test_sds.copy(deepcopy=True)\n",
    "X_test = test_sds_pred.features\n",
    "y_test = test_sds.labels\n",
    "test_probs = model_fair.predict_proba(X_test)[:, 1]\n",
    "test_pred = test_probs > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse fairness and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test.race_white == 1\n",
    "\n",
    "bl_acc = accuracy(test.employed_yes, bl_test_probs)\n",
    "bl_dpd = demographic_parity_difference(\n",
    "    test.employed_yes, bl_test_pred, sensitive_features=test.race_white,\n",
    ")\n",
    "\n",
    "acc = accuracy(test.employed_yes, test_probs)\n",
    "dpd = demographic_parity_difference(\n",
    "    test.employed_yes, test_pred, sensitive_features=test.race_white,\n",
    ")\n",
    "\n",
    "print(f\"Baseline model accuracy: {bl_acc:.3f}\")\n",
    "print(f\"Model accuracy: {acc:.3f}\")\n",
    "\n",
    "print(f\"Baseline demographic parity difference: {bl_dpd:.3f}\")\n",
    "print(f\"Model demographic parity difference: {dpd:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_box = group_box_plots(\n",
    "    np.concatenate([bl_test_probs, test_probs]),\n",
    "    np.tile(test.race_white.map({0: \"Black\", 1: \"White\"}), 2),\n",
    "    groups=np.concatenate(\n",
    "        [\n",
    "            np.zeros_like(bl_test_probs),\n",
    "            np.ones_like(test_sds_pred.scores.flatten()),\n",
    "        ]\n",
    "    ),\n",
    "    group_names=[\"Baseline\", \"Kamiran-Calders\"],\n",
    "    title=\"Score by race for model and baseline\",\n",
    "    xlabel=\"Score\",\n",
    "    ylabel=\"Method\",\n",
    ")\n",
    "dp_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(dp_box, \"kamiran-calders-dp.json\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
