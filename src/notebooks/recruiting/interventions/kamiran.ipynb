{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label modifcation by Kamiran et al. - Recruiting data\n",
    "\n",
    "This notebook contains the implementation of the post-processing label modification algorithm introduced in [Decision Theory for Discrimination-aware Classification](https://ieeexplore.ieee.org/abstract/document/6413831) by Kamiran et al. (2012) as part of the IBM AIF360 fairness tool box github.com/IBM/AIF360.\n",
    "\n",
    "The intervention method identifies a low-confidence subset of the data for probabilistic classifiers, and produces new predicted labels for this subset by assigning positive labels to the unprivileged group and negative labels to the privileged group. Different notions of fairness can be achieved in this way, including demographic parity, equalised odds and equal opportunity, of which each one is allowed in the implementation. In this notebook we demonstrate each of these three definitions as a result of the fairness intervention. \n",
    "\n",
    "For simplicity, we'll focus mitigating bias with resepct to sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import (\n",
    "    RejectOptionClassification,\n",
    ")\n",
    "from aif360.datasets import StandardDataset\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,\n",
    "    equalized_odds_difference,\n",
    ")\n",
    "from helpers.metrics import accuracy\n",
    "from helpers.plot import group_bar_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "from helpers import export_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We have committed preprocessed data to the repository for reproducibility and we load it here. Check out the preprocessing notebook for details on how this data was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# override data_dir in source notebook\n",
    "# this is stripped out for the hosted notebooks\n",
    "artifacts_dir = Path(\"../../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"recruiting\"\n",
    "\n",
    "train = pd.read_csv(data_dir / \"processed\" / \"train.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process data for our fairness intervention we need to define special dataset objects which are part of every intervention pipeline within the IBM AIF360 toolbox. These objects contain the original data as well as some useful further information, e.g., which feature is the protected attribute as well as which column corresponds to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "index = train_sds.feature_names.index(\"race_white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which binary value goes with the (un-)privileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"race_white\": 1.0}]\n",
    "unprivileged_groups = [{\"race_white\": 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train unfair model\n",
    "\n",
    "For maximum reproducibility we load the baseline model from disk, but the code used to train can be found in the baseline model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = joblib.load(\n",
    "    artifacts_dir / \"models\" / \"recruiting\" / \"baseline.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_val_probs = baseline_model.predict_proba(val.drop(\"employed_yes\", axis=1))[\n",
    "    :, 1\n",
    "]\n",
    "val_sds_pred = val_sds.copy(deepcopy=True)\n",
    "val_sds_pred.scores = bl_val_probs.reshape(-1, 1)\n",
    "\n",
    "bl_test_probs = baseline_model.predict_proba(\n",
    "    test.drop(\"employed_yes\", axis=1)\n",
    ")[:, 1]\n",
    "bl_test_pred = bl_test_probs > 0.5\n",
    "test_sds_pred = test_sds.copy(deepcopy=True)\n",
    "test_sds_pred.scores = bl_test_probs.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic parity\n",
    "\n",
    "We first address demographic parity. In order to do so, we learn the label modification algorithm based on the true and predicted labels of the validation data. We then apply the learnt intervention to the predictions of the test data and analyse the outcomes for fairness and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used\n",
    "metric_name = \"Statistical parity difference\"  # Alias for demographic parity\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn intervention on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    low_class_thresh=0.01,\n",
    "    high_class_thresh=0.99,\n",
    "    num_class_thresh=100,\n",
    "    num_ROC_margin=50,\n",
    "    metric_name=metric_name,\n",
    "    metric_ub=metric_ub,\n",
    "    metric_lb=metric_lb,\n",
    ")\n",
    "ROC = ROC.fit(val_sds, val_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply intervention on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set\n",
    "test_sds_pred_transf = ROC.predict(test_sds_pred).copy(deepcopy=True)\n",
    "test_pred_labels = test_sds_pred_transf.labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse fairness and accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.drop(columns=[\"race_white\", \"employed_yes\"]).values\n",
    "test_race = test.race_white.values\n",
    "test_employed = test.employed_yes.values\n",
    "mask = test_race == 1\n",
    "\n",
    "# baseline metrics\n",
    "bl_test_acc = accuracy(test_employed, bl_test_probs)\n",
    "bl_test_dpd = demographic_parity_difference(\n",
    "    test.employed_yes, bl_test_pred, sensitive_features=test_race,\n",
    ")\n",
    "\n",
    "# new model metrics\n",
    "test_acc = accuracy(test_employed, test_pred_labels)\n",
    "test_dpd = demographic_parity_difference(\n",
    "    test.employed_yes, test_pred_labels, sensitive_features=test_race,\n",
    ")\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline demographic parity: {bl_test_dpd:.3f}\")\n",
    "print(f\"Demographic parity: {test_dpd:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider accuracy on the white / black subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_acc = accuracy(\n",
    "    test_pred_labels[test.race_white == 1],\n",
    "    test.employed_yes[test.race_white == 1],\n",
    ")\n",
    "black_acc = accuracy(\n",
    "    test_pred_labels[test.race_white == 0],\n",
    "    test.employed_yes[test.race_white == 0],\n",
    ")\n",
    "\n",
    "mean_black_score = test_pred_labels[test.race_white == 0].mean()\n",
    "mean_white_score = test_pred_labels[test.race_white == 1].mean()\n",
    "\n",
    "print(f\"Black accuracy: {black_acc:.3f}\")\n",
    "print(f\"White accuracy: {white_acc:.3f}\")\n",
    "print(f\"Mean black score: {mean_black_score:.3f}\")\n",
    "print(f\"Mean white score: {mean_white_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_bar = group_bar_plots(\n",
    "    test_pred_labels,\n",
    "    test.race_white.map({0: \"Black\", 1: \"White\"}),\n",
    "    title=\"Predictions by race\",\n",
    "    xlabel=\"Proportion predicted successful\",\n",
    ")\n",
    "dp_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(dp_bar, \"kamiran-dp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalised Odds\n",
    "\n",
    "We'll now repeat the process for equalised odds, which requires us changing the underlying metric which leads to learning the correction according a new decision threshold addressing equalised odds. There are no further modifcations to the existing parameter choices required. However we apply smaller bounds on equalised odds than for demographic parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used\n",
    "metric_name = \"Average odds difference\"  # alias for equalised odds\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.01\n",
    "metric_lb = -0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn intervention on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    low_class_thresh=0.01,\n",
    "    high_class_thresh=0.99,\n",
    "    num_class_thresh=100,\n",
    "    num_ROC_margin=50,\n",
    "    metric_name=metric_name,\n",
    "    metric_ub=metric_ub,\n",
    "    metric_lb=metric_lb,\n",
    ")\n",
    "ROC = ROC.fit(val_sds, val_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply intervention on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set\n",
    "test_sds_pred_transf = ROC.predict(test_sds_pred).copy(deepcopy=True)\n",
    "test_pred_labels = test_sds_pred_transf.labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse fairness and accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.drop(columns=[\"race_white\", \"employed_yes\"]).values\n",
    "test_race = test.race_white.values\n",
    "test_employed = test.employed_yes.values\n",
    "mask = test_race == 1\n",
    "\n",
    "# baseline metrics\n",
    "bl_test_acc = accuracy(test_employed, bl_test_probs)\n",
    "bl_test_eod = equalized_odds_difference(\n",
    "    test_employed, bl_test_pred, sensitive_features=test_race,\n",
    ")\n",
    "\n",
    "# new model metrics\n",
    "test_acc = accuracy(test_employed, test_pred_labels)\n",
    "test_eod = equalized_odds_difference(\n",
    "    test_employed, test_pred_labels, sensitive_features=test_race,\n",
    ")\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline equalised odds (dist.): {bl_test_eod:.3f}\")\n",
    "print(f\"Equalised odds (dist.): {test_eod:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_bar = group_bar_plots(\n",
    "    test_pred_labels,\n",
    "    test.race_white.map({0: \"Black\", 1: \"White\"}),\n",
    "    groups=test.employed_yes,\n",
    "    group_names=[\"Not employed\", \"Employed\"],\n",
    "    title=\"Predictions by race and outcome\",\n",
    "    xlabel=\"Proportion predicted successful\",\n",
    "    ylabel=\"Outcome\",\n",
    ")\n",
    "eo_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(eo_bar, \"kamiran-eo.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal opportunity\n",
    "\n",
    "We'll now repeat the process for equal opportunity, which only requires us changing the underlying metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric used\n",
    "metric_name = \"Equal opportunity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.01\n",
    "metric_lb = -0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn interrvention on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = RejectOptionClassification(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    "    low_class_thresh=0.01,\n",
    "    high_class_thresh=0.99,\n",
    "    num_class_thresh=100,\n",
    "    num_ROC_margin=50,\n",
    "    metric_name=metric_name,\n",
    "    metric_ub=metric_ub,\n",
    "    metric_lb=metric_lb,\n",
    ")\n",
    "ROC = ROC.fit(val_sds, val_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply intervention on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set\n",
    "test_sds_pred_transf = ROC.predict(test_sds_pred).copy(deepcopy=True)\n",
    "test_pred_labels = test_sds_pred_transf.labels.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse fairness and accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.drop(columns=[\"race_white\", \"employed_yes\"]).values\n",
    "test_race = test.race_white.values\n",
    "test_employed = test.employed_yes.values\n",
    "mask = test_race == 1\n",
    "\n",
    "# baseline metrics\n",
    "bl_test_acc = accuracy(test_employed, bl_test_probs)\n",
    "bl_test_eoppd = equalized_odds_difference(\n",
    "    test_employed[test.employed_yes == 1],\n",
    "    bl_test_pred[test.employed_yes == 1],\n",
    "    sensitive_features=test_race[test.employed_yes == 1],\n",
    ")\n",
    "\n",
    "# new model metrics\n",
    "test_acc = accuracy(test_employed, test_pred_labels)\n",
    "test_eoppd = equalized_odds_difference(\n",
    "    test_employed[test.employed_yes == 1],\n",
    "    test_pred_labels[test.employed_yes == 1],\n",
    "    sensitive_features=test_race[test.employed_yes == 1],\n",
    ")\n",
    "\n",
    "print(f\"Baseline accuracy: {bl_test_acc:.3f}\")\n",
    "print(f\"Accuracy: {test_acc:.3f}\\n\")\n",
    "\n",
    "print(f\"Baseline equal opportunity: {bl_test_eoppd:.3f}\")\n",
    "print(f\"Equal opportunity: {test_eoppd:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eopp_bar = group_bar_plots(\n",
    "    test_pred_labels[test.employed_yes == 1],\n",
    "    test.race_white[test.employed_yes == 1].map({0: \"Black\", 1: \"White\"}),\n",
    "    title=\"Predictions by race for successful applicants\",\n",
    "    xlabel=\"Proportion predicted successful\",\n",
    ")\n",
    "eopp_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "export_plot(eopp_bar, \"kamiran-eopp.json\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
