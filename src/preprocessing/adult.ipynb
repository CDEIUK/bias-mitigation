{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult preprocessing\n",
    "\n",
    "This notebook contains all preprocessing of the [Adult dataset](https://archive.ics.uci.edu/ml/datasets/Adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are available in the [`adult.names`](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) file which contains lots of additional information. We hard code them here for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"salary\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data contains a \"native country\" feature. Other than USA and Mexico, many of the features have low numbers of observations, so we group them into a single category using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    \"\"\"\n",
    "    Helper function that strips leading / trailing whitespace, lower\n",
    "    cases, and replaces hyphens with underscores.\n",
    "    \"\"\"\n",
    "    return s.strip().lower().replace(\"-\", \"_\")\n",
    "\n",
    "\n",
    "def parse_native_country(country):\n",
    "    \"\"\"\n",
    "    Group countries other than United-States and Mexico into single\n",
    "    \"other\" category\"\n",
    "    \"\"\"\n",
    "    country = clean_string(country)\n",
    "    if country == \"united_states\" or country == \"mexico\":\n",
    "        return country\n",
    "    return \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train set and apply some basic preprocessing. Categorical features are left as strings for now to be one-hot encoded shortly. We drop `fnlwgt` as it represents census weights that are not relevant to our analysis, and `education-num` as it duplicates data present in the `education` feature which we use instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (\n",
    "    pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        header=None,\n",
    "        na_values=[\" ?\"],\n",
    "        names=names,\n",
    "    )\n",
    "    .drop(columns=[\"fnlwgt\", \"education_num\"])\n",
    "    # drop all rows with missing values\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    "    # simple preprocessing on columns\n",
    "    .assign(\n",
    "        # clean all string columns\n",
    "        education=lambda df: df.education.map(clean_string),\n",
    "        marital_status=lambda df: df.marital_status.map(clean_string),\n",
    "        occupation=lambda df: df.occupation.map(clean_string),\n",
    "        race=lambda df: df.race.map(clean_string),\n",
    "        relationship=lambda df: df.relationship.map(clean_string),\n",
    "        workclass=lambda df: df.workclass.map(clean_string),\n",
    "        # clean and aggregate native_country\n",
    "        native_country=lambda df: df.native_country.map(parse_native_country),\n",
    "        # encode binary features as integers\n",
    "        salary=lambda df: (df.salary == \" >50K\").astype(np.int32),\n",
    "        sex=lambda df: (df.sex == \" Male\").astype(np.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test set and apply similar basic preprocessing. Note `adult.test` file has an extra line at the start of the file we ignore, and that the `salary` column is coded differently to `adult.data` in a subtle way (has an extra `.`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (\n",
    "    pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "        header=None,\n",
    "        na_values=[\" ?\"],\n",
    "        skiprows=1,\n",
    "        names=names,\n",
    "    )\n",
    "    .drop(columns=[\"fnlwgt\", \"education_num\"])\n",
    "    # drop all rows with missing values\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    "    # simple preprocessing on columns\n",
    "    .assign(\n",
    "        # clean all string columns\n",
    "        education=lambda df: df.education.map(clean_string),\n",
    "        marital_status=lambda df: df.marital_status.map(clean_string),\n",
    "        occupation=lambda df: df.occupation.map(clean_string),\n",
    "        race=lambda df: df.race.map(clean_string),\n",
    "        relationship=lambda df: df.relationship.map(clean_string),\n",
    "        workclass=lambda df: df.workclass.map(clean_string),\n",
    "        # clean and aggregate native_country\n",
    "        native_country=lambda df: df.native_country.map(parse_native_country),\n",
    "        # encode binary features as integers\n",
    "        # note extra '.' in test set not present in train set\n",
    "        salary=lambda df: (df.salary == \" >50K.\").astype(np.int32),\n",
    "        sex=lambda df: (df.sex == \" Male\").astype(np.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that categories in categorical variables are the same for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(train.education) == set(test.education)\n",
    "assert set(train.race) == set(test.race)\n",
    "assert set(train.relationship) == set(test.relationship)\n",
    "assert set(train.marital_status) == set(test.marital_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_features = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"occupation\",\n",
    "    \"race\",\n",
    "    \"relationship\",\n",
    "    \"marital_status\",\n",
    "    \"native_country\",\n",
    "]\n",
    "\n",
    "cts_features = [\"age\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "\n",
    "binary_features = [\"sex\", \"salary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We one-hot encode categorical features. We'll keep both one-hot encodings and the original categorical encodings for now, as we want to construct two versions of the data, one for training the model on, and one for making visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat(\n",
    "    [train, pd.get_dummies(train.loc[:, one_hot_features], dtype=np.int32)],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "test_df = pd.concat(\n",
    "    [test, pd.get_dummies(test.loc[:, one_hot_features], dtype=np.int32)],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that the columns are the same (including order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_df.columns.tolist() == test_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further split the train set to create a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all splits to disk without one-hot encodings. This version of the data will be used for exploration and making plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary platform specific directory\n",
    "data_dir = Path(\"/project/data/adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = cts_features + one_hot_features + binary_features\n",
    "\n",
    "train_df[original_features].to_csv(\n",
    "    data_dir / \"processed\" / \"train.csv\", index=False\n",
    ")\n",
    "val_df[original_features].to_csv(\n",
    "    data_dir / \"processed\" / \"val.csv\", index=False\n",
    ")\n",
    "test_df[original_features].to_csv(\n",
    "    data_dir / \"processed\" / \"test.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now scale the continuous features and drop the categorical encodings, which will be used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "train_df[cts_features] = ss.fit_transform(train_df[cts_features])\n",
    "val_df[cts_features] = ss.transform(val_df[cts_features])\n",
    "test_df[cts_features] = ss.transform(test_df[cts_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=one_hot_features).to_csv(\n",
    "    data_dir / \"processed\" / \"train-one-hot.csv\", index=False\n",
    ")\n",
    "val_df.drop(columns=one_hot_features).to_csv(\n",
    "    data_dir / \"processed\" / \"val-one-hot.csv\", index=False\n",
    ")\n",
    "test_df.drop(columns=one_hot_features).to_csv(\n",
    "    data_dir / \"processed\" / \"test-one-hot.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
