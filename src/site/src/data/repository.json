[
  {
    "unique-id": 1,
    "who": "Alan Turing Insitute",
    "use-case-type": "",
    "use-case-sub-type": "",
    "sector": "Health and Social Care",
    "description": "A research paper by the Alan Turing Institute proposes a design for health certificates called 'health tokens' as a non-discriminatory solution to the COVID-19 immunity passports problem. These health certificates would be created using differential privacy methods, allowing individual test results to be randomised while still allowing for aggregate level estimates of risk to be calculated. The research suggests that health tokens could mitigate discrimination based on immunity and tackle concerns around the creation of an 'immuno-privileged' class. However, it would still offer valuable information on collective transmission risk posed by small groups. The paper presents the results of an open-source prototype. ",
    "stage-of-dev": "Proof of concept",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "DP",
    "pets2": "",
    "pets3": "",
    "link1": "Alan Turing Institute",
    "link2": "",
    "link3": "",
    "link1URL": "https://www.turing.ac.uk/research/publications/differentially-private-health-tokens-estimating-covid-19-risk",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 2,
    "who": "Apple",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to to train personalised systems without having to gather personal data from individuals",
    "sector": "Digital",
    "description": "Apple has leveraged federated learning to train the voice recognition software used by its AI Assistant, Siri. A local model is trained on an individual's iPhone, and the resulting model weights are periodically communicated back to a central server, which builds a global model by aggregating the weights from the local models. This global model is pushed out to users' iPhones, and the process repeats. Noise is injected during the training of the local model to ensure it is differentially private, so as to mitigate the risk of reidentification. Using this system, Siri can learn to recognise the voice of the iPhone owner, so that it only responds to them, without Apple collecting any raw data relating to the users' voice.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "FA",
    "pets2": "DP",
    "pets3": "",
    "link1": "MIT Tech Review",
    "link2": "Apple: Learning with privacy at scale",
    "link3": "",
    "link1URL": "https://www.technologyreview.com/2019/12/11/131629/apple-ai-personalizes-siri-federated-learning/",
    "link2URL": "https://machinelearning.apple.com/research/learning-with-privacy-at-scale",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 3,
    "who": "Apple/Google contact tracing API",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "Developed in response to the COVID-19 pandemic, Apple and Google collaborated to develop a privacy-preserving architecture facilitating digital contract tracing based on bluetooth proximity information. Access to the system is only made available to health authorities, who develop their own apps leveraging the Apple/Google APIs (for example the NHS app in England Wales). Mobiles phones with the app enabled exchange random identifiers (each phone's identifier changes frequently) when in close proximity. Following a positive test, a user consents to upload details of their device's identifiers from recent days to a central server managed by the health authority. All phones periodically download this list of identifiers corresponding to positive tests from the central server, and receive an alert to self-isolate if there is a match with the identifiers of close contacts stored on their device. ",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "FA",
    "pets2": "De-ID",
    "pets3": "",
    "link1": "Google",
    "link2": "Apple",
    "link3": "",
    "link1URL": "https://www.google.com/covid19/exposurenotifications/#exposure-notifications-and-privacy",
    "link2URL": "https://covid19.apple.com/contacttracing",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 4,
    "who": "AUSTRAC",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "As a regulator, I want to identify illegal online activity that is coordinated across institutions, whilst ensuring that sensitive information held by each institution is not revealed",
    "sector": "Finance",
    "description": "Developing federated system to identify suspicious financial activities carried out by individuals or groups across a number of financial institutions. Aim to be able to gather insights from over 100 million accounts.",
    "stage-of-dev": "In development",
    "he": "x",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "MPC",
    "pets3": "",
    "link1": "LinkedIn",
    "link2": "FFIS",
    "link3": "",
    "link1URL": "https://www.linkedin.com/pulse/australia-unveils-world-first-privacy-preserving-fintel-nathan-lynch/",
    "link2URL": "https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_innovation_and_discussion_paper_-_case_studies_of_the_use_of_privacy_preserving_analysis.pdf",
    "link3URL": "",
    "kw1": "#fraud",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 5,
    "who": "Boston Women's Workforce Council (BWWC) and Boston University's Hariri Institute for Computing",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "As a regulator, I want to identify illegal online activity that is coordinated across institutions, whilst ensuring that sensitive information held by each institution is not revealed",
    "sector": "Other",
    "description": "The BWWC began using an MPC system developed in partnership with the Hariri Institute in 2017 to enable organisations to anonymously report gender pay gap information. The data collected included gender, ethnicity, length of service, annual compensation, and performance pay. The latest report, produced in 2019, includes data for 136,437 employees from 123 organisations, representing 13% of the Greater Boston workforce.  The confidentiality provided by the MPC solution has encouraged a greater number of companies to participate in the study, increasing from 69 companies in 2016 to 123 in 2019. User experience was also important in encouraging participation, with the user interface providing a familiar spreadsheet that can be filled with data manually or via copy-paste. The statistics derived through this process have shown that the gender pay gap in the Boston area is even larger than previously estimated by the U.S. Bureau of Labor Statistics.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "MPC",
    "pets2": "",
    "pets3": "",
    "link1": "BWWC",
    "link2": "IEEE Conference Paper",
    "link3": "",
    "link1URL": "https://thebwwc.org/mpc",
    "link2URL": "https://ieeexplore.ieee.org/abstract/document/7839796",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 6,
    "who": "Danisco and the Association of Sugar Beet Growers",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "As an economist/policy advisor/minister, I want to derive performance metrics about a sector, whilst preserving the privacy of commercially sensitive information held by organisations in that sector",
    "sector": "Other",
    "description": "Sugar beet farmers in Denmark have contracts determining how much beet they produce. All beet produced goes to Danisco, the only sugar producer in Denmark. The EU significantly reduced beet subsidies, meaning the country needed to develop a competitive market for trading production rights. A system was developed leveraging multi-party computation to enable confidential bidding to compute a trading price based on supply and demand. This enabled the production quota to be redistributed accordingly, whilst details of individual beet farmers bids remained confidential - 80% of farmers surveyed that this confidentiality was important to them. The first auction took place in 2008, and is considered the first large-scale, practical application of MPC.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "MPC",
    "pets2": "",
    "pets3": "",
    "link1": "Report",
    "link2": "",
    "link3": "",
    "link1URL": "https://eprint.iacr.org/2008/068.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 7,
    "who": "Duality Technologies",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "A framework for genome-wide association studies that leverages homomorphic encryption to keep medical and genomic data secure. The framework has been applied to conduct GWAS of age-related macular degeneration on a dataset of over 25,000 individuals. The sytem is ~30 times faster than state of the art GWAS schemes based on multi-party computation.",
    "stage-of-dev": "Proof of concept",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "",
    "pets3": "",
    "link1": "Original paper",
    "link2": "PR Newswire",
    "link3": "",
    "link1URL": "https://www.pnas.org/content/117/21/11608",
    "link2URL": "https://www.prnewswire.com/il/news-releases/duality-technologies-researchers-accelerate-privacy-enhanced-collaboration-on-genomic-data--with-significant-implications-for-covid-19-research-301059258.html",
    "link3URL": "",
    "kw1": "#GWAS",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 8,
    "who": "Duality Technologies",
    "use-case-type": "secure_data_processing",
    "use-case-sub-type": "",
    "sector": "Finance",
    "description": "This project allows a party to query data that is owned by another party and receive the results without any sensitive parameters being disclosed to the external data owner. It aims to accelerate triage in fraud and anti-money laundering (AML) investigations. The privacy of the entity and the investigation is preserved throughout, even when complex SQL-like queries are made. ",
    "stage-of-dev": "Proof of concept",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "",
    "pets3": "",
    "link1": "RUSI-FFIS report (Chapter 7)",
    "link2": "",
    "link3": "",
    "link1URL": "https://www.gcffc.org/wp-content/uploads/2020/06/FFIS-Innovation-and-discussion-paper-Case-studies-of-the-use-of-privacy-preserving-analysis.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 9,
    "who": "Enveil Inc.",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "",
    "sector": "Finance",
    "description": "Enveil has designed and developed an approach for financial institutions to identify matching customer information in external datasets without disclosing information about that customer. This allows financial institutions to investigate suspicious activity without revealing personal information, especially in the case that the customer being investigated is ultimately innocent. This proof of concept has been executed using synthetic data and also showed that information can still be made visible for audit, tracebeility and trust building where required. ",
    "stage-of-dev": "Proof of concept",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "",
    "pets3": "",
    "link1": "RUSI-FFIS report (Chapter 7)",
    "link2": "",
    "link3": "",
    "link1URL": "https://www.gcffc.org/wp-content/uploads/2020/06/FFIS-Innovation-and-discussion-paper-Case-studies-of-the-use-of-privacy-preserving-analysis.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 10,
    "who": "Estonian Association of Information Technology and Telecommunications (ITL)",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "As an economist/policy advisor/minister, I want to derive performance metrics about a sector, whilst preserving the privacy of commercially sensitive information held by organisations in that sector",
    "sector": "Other",
    "description": "In 2011, ITL proposed collecting key financial metrics from its member companies in order to better understand the state of the telecoms sector. Members expressed concern over the confidentiality of the metrics, as they would be sharing them with competitors. ITL chose to partner with cybersecurity firm Cybernetica, who were able to deploy their Sharemind secure computing platform to enable the analysis to be done whilst protecting confidentiality. 17 companies participated, uploading their metrics to the Sharemind platform, which distributed the data across three “computing parties” (CPs). These CPs performed the desired analysis, using a multi-party computation protocol to ensure confidentiality. The final results of the analysis were shared with the ITL, who disseminated accordingly. The distributed nature of the computation meant no party, including the ITL, ever had direct access to another party’s metrics.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "MPC",
    "pets2": "",
    "pets3": "",
    "link1": "Royal Society report on PETs",
    "link2": "Academic paper",
    "link3": "",
    "link1URL": "https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf",
    "link2URL": "https://academic.oup.com/comjnl/article/61/12/1749/5095655",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 11,
    "who": "Facebook",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller/processor, I want to be able to share aggregate data/statistics with a party/parties/the public such that personal information in the dataset cannot be reverse-engineered",
    "sector": "Digital",
    "description": "In 2018, Facebook established an initiative to provide researchers access to data in order to study the role of social media in elections and democratic discourse. Data was shared with 60 researchers, and consisted of links that had been shared publicly on Facebook by at least 100 unique Facebook users. In 2020, the size of the shared dataset was substantially increased to include approximately 38 million such links, with new aggregated information to help researchers analyze how many people saw these links on Facebook and how they interacted with that content – including views, clicks, shares, likes, and other reactions. The data shared was also aggregated by age, gender, country, and month. Facebook leveraged differential privacy to provide privacy guarantees to individuals in the dataset.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "DP",
    "pets2": "",
    "pets3": "",
    "link1": "Facebook blog",
    "link2": "Technical report",
    "link3": "",
    "link1URL": "https://research.fb.com/blog/2020/02/new-privacy-protected-facebook-data-for-independent-research-on-social-medias-impact-on-democracy/",
    "link2URL": "https://arxiv.org/pdf/2002.04049.pdf",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 12,
    "who": "Google",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller/processor, I want to be able to share aggregate data/statistics with a party/parties/the public such that personal information in the dataset cannot be reverse-engineered",
    "sector": "Health and Social Care",
    "description": "A publicly available resource of statistics and visualisations intended to show the changes in the population’s mobility habits in response to COVID-19 interventions, based on location data from Google users opted in to location history tracking. Differential privacy is used to protect two metrics: the details of the location a user visited, and the number of visits the user made to each location.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "DP",
    "pets2": "",
    "pets3": "",
    "link1": "Google blog",
    "link2": "Technical paper",
    "link3": "",
    "link1URL": "https://www.blog.google/technology/health/covid-19-community-mobility-reports",
    "link2URL": "https://arxiv.org/pdf/2004.04145.pdf",
    "link3URL": "",
    "kw1": "#COVID",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 13,
    "who": "Google",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to to train personalised systems without having to gather personal data from individuals",
    "sector": "Digital",
    "description": "GBoard is a keyboard app for Android and iOS devices. It features next-word prediction, driven by a machine learning model. GBoard utilises federated learning, where each mobile device downloads an initial model from a central server, which is further trained on the device using user data local to the device. The weights of the resulting model are periodically communicated back to the central server using a secure aggregation protocol (a form of multi-party computation), which aggregates the weights received from all mobile devices into a new common model. Devices download this new model, and the cycle repeats, such that the model is continuously trained without collecting user data centrally.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "x",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "MPC",
    "pets2": "FA",
    "pets3": "",
    "link1": "Google blog",
    "link2": "Technical paper",
    "link3": "",
    "link1URL": "https://ai.googleblog.com/2017/04/federated-learning-collaborative.html",
    "link2URL": "https://arxiv.org/pdf/1811.03604.pdf",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 14,
    "who": "Google",
    "use-case-type": "",
    "use-case-sub-type": "",
    "sector": "Digital",
    "description": "In order to compute accurate conversion rates from advertisements to actual purchases, Google computes the size of the intersection between the list of people shown an advertisement to the list of people actually purchasing the advertised goods. When the goods are not purchased online and so the purchase connection to the shown advertisement cannot be tracked, Google and the company paying for the advertisement have to share their respective lists in order to compute the intersection size. In order to compute this without revealing anything but the size of the intersection, Google utilises a protocol for privacy-preserving set intersection. Although this protocol is far from the most efficient known today, it is simple and meets their computational requirements.",
    "stage-of-dev": "Product",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "",
    "pets3": "",
    "link1": "Google paper",
    "link2": "",
    "link3": "",
    "link1URL": "https://eprint.iacr.org/2017/738.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 15,
    "who": "Indian Insitute of Science's",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "",
    "sector": "Transport",
    "description": "In response to the Indian government increasing research into unmanned aerial vehicles (UAVs) and remotely piloted vehicles (RPVs), the Indian Institute of Science's (IISc) has developed \"Privaros\" which a set of enhancements to drone software stack designed to mitigate privacy concerns around the many sensors, cameras, microphones and GPS capabilities that drones are equipped with. Privaros allows a host airspace, such as apartment complexes, university campuses and city municipalities, to determine their own privacy policies and ensure commercial delivery drones are compliant. The working prototype is equipped with a hardware trusted execution environment (TEE) unlike most off-the-shelf drones. Evaluation shows that a drone running Privaros can robusts enforce various privacy policies specificied by hosts with marginal increases to communication latency and power consumption. ",
    "stage-of-dev": "Proof of concept",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "x",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "TEE",
    "pets2": "",
    "pets3": "",
    "link1": "Times of India",
    "link2": "",
    "link3": "",
    "link1URL": "https://timesofindia.indiatimes.com/india/as-drones-get-ready-to-deliver-iisc-finds-way-to-aid-privacy/articleshow/80738756.cms",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 16,
    "who": "Inpher Inc.",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "",
    "sector": "Finance",
    "description": "This project allowed a subsidiary of a large bank to build a machine-learning sales prediction model using data from other subsidiaries of the same bank located in other countries. The product ensured that there was no cross-border disclosure of the data contributing to the algorithm, enabling the subsidiary in question to exploit 300,000 more data points when training the model. The analyst doing the computation only saw the outputs of the model. The inputs were encrypted throughout the process. This product has been commercially deployed and can run on real customer data. There have been so data interoperability issues, enabling full use of distributed datasets. ",
    "stage-of-dev": "Product",
    "he": "x",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "MPC",
    "pets3": "",
    "link1": "RUSI-FFIS report (Chapter 7)",
    "link2": "",
    "link3": "",
    "link1URL": "https://www.gcffc.org/wp-content/uploads/2020/06/FFIS-Innovation-and-discussion-paper-Case-studies-of-the-use-of-privacy-preserving-analysis.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 17,
    "who": "IQVIA",
    "use-case-type": "",
    "use-case-sub-type": "",
    "sector": "Health and Social Care",
    "description": "E360 Genomics uses a form of secure computation (tokenization of variants, multi-party is desired, and cell-size rules on statistical outputs). This is being leveraged by Genomics England.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "MPC",
    "pets2": "De-ID",
    "pets3": "",
    "link1": "Bio-IT World",
    "link2": "IQVIA",
    "link3": "",
    "link1URL": "https://www.bio-itworld.com/news/2019/04/24/de-identifying-genomic-data-with-hashing-technology",
    "link2URL": "https://www.iqvia.com/solutions/innovative-models/genomics",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 18,
    "who": "Microsoft",
    "use-case-type": "secure_data_processing",
    "use-case-sub-type": "As a data controller and processor, I want to conduct my own processing within an environment that I do not fully trust, such as a cloud provider’s infrastructure",
    "sector": "Digital",
    "description": "The Confidential Consortium Blockchain Framework (CCBF) is a system using trusted execution environments that facilitates confidentiality within a blockchain network. To prevent malicious behaviours, blockchains were designed so that all transactions are recorded and open for all to see and replicated across hundreds of decentralised nodes for integrity. Within CCBF, confidentiality is provided by TEEs that can process transactions encrypted using keys accessible only to a CCBF node of a specific CCBF service. Besides confidentiality, TEEs also provide publicly verifiable artefacts, called quotes, that certify that the TEE is running a specific code. Hence, integrity of transaction evaluation in CCBF can be verified via quotes and not be replicated across mutually untrusted nodes as it is done in public blockchains. It is worth pointing out that transaction data is replicated in CCBF across a small network of nodes, each executing in a TEE, but for the purpose of fault-tolerance rather than integrity. In addition, Microsoft’s test showed that the CCBF could process 50,000+ transactions per second, demonstrating the scalability of the technology. As a comparison, the public blockchain Ethereum network has an average processing rate of 20 transactions per second, whilst the Visa credit card processing system averages 2,000 transactions per second.  The framework is not a standalone blockchain protocol, but rather it provides trusted foundations that can support any existing blockchain protocol.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "x",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "TEE",
    "pets2": "",
    "pets3": "",
    "link1": "Royal Society report on PETs",
    "link2": "GitHub repository",
    "link3": "Technical report",
    "link1URL": "https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf",
    "link2URL": "https://github.com/Microsoft/CCF",
    "link3URL": "https://github.com/microsoft/CCF/blob/main/CCF-TECHNICAL-REPORT.pdf",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 19,
    "who": "Microsoft",
    "use-case-type": "",
    "use-case-sub-type": "",
    "sector": "Digital",
    "description": "Microsoft Viva is an Employee Experience Platform (EXP) that brings together communications, learning, resources and analytics. There are four sub-services on the platform called Insights, Topics, Learning and Connections. Viva Insights gives employees and managers personalised and actionable insights on various organisational metrics that can help drive productivity and wellbeing experience. The Insights tool uses safeguards like de-identification and differential privacy by default so that personal insights are only available at the individual level and not for managers or leaders of an organisation. ",
    "stage-of-dev": "",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "DP",
    "pets2": "De-ID",
    "pets3": "",
    "link1": "Microsoft Tech Community",
    "link2": "Microsoft Blog Post Announcement",
    "link3": "",
    "link1URL": "https://techcommunity.microsoft.com/t5/microsoft-teams-blog/introducing-microsoft-viva-the-employee-experience-platform-in/ba-p/2111481",
    "link2URL": "https://techcommunity.microsoft.com/t5/microsoft-viva-blog/microsoft-viva-insights-helps-people-nurture-wellbeing-and-be/ba-p/2107010",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 20,
    "who": "Microsoft",
    "use-case-type": "",
    "use-case-sub-type": "",
    "sector": "Digital",
    "description": "Microsoft has rolled out Password Generator and Password Monitor features in its Edge browser, using a homomorphic encryption service. The password manager collects saved passwords in one place and the monitor alerts the user if passwords have been compromised. The use of homomorphic encryption means that Microsoft never has to decrypt the data, in other words never has access to the actual credentials, but is still able to query the data. The encryption technoogy was developed by the product team in collaboration with the Cryptography and Privacy Research Group at Microsoft. ",
    "stage-of-dev": "Product",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "",
    "pets3": "",
    "link1": "Yahoo news",
    "link2": "",
    "link3": "",
    "link1URL": "https://in.news.yahoo.com/microsofts-password-monitor-feature-coming-071406870.html",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 21,
    "who": "Netherlands Organisation for Applied Scientific Research (TNO)",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "As part of the BigMedilytics project, funded by the EU's Horizon 2020 program, TNO developed a system to identify patients at risk of heart failure by confidentially combining data of potential indicators held by different organisations, leveraging an MPC protocol. The Erasmus MC hospital holds data on the lifestyle of patients, and insurance company Zilverin Kruis holds data on attributes such as hospitalization days and health care usage. The solution consists of two phases. First, a secure inner join protocol is used to identify which patients are present in both datasets. Both parties homomorphically encrypt attributes of the dataset which are sent to a third party, which determines the intersection of the datasets (the third party cannot access the raw data directly, since it's homomorphically encrypted). The encrypted intersection is split into 3 secret shares, which are split across the 3 parties, and an MPC protocol is used to train a regression model. Erasmus MC and Zilverin Krius receive the coefficients of the regression, which they can then use to predict the risk of individual patients.",
    "stage-of-dev": "Proof of concept",
    "he": "x",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "HE",
    "pets2": "MPC",
    "pets3": "De-ID",
    "link1": "Youtube",
    "link2": "Medium blog",
    "link3": "",
    "link1URL": "https://www.youtube.com/watch?v=hvBb80eXuZg&feature=youtu.be",
    "link2URL": "https://medium.com/applied-mpc/identifying-heart-failure-patients-at-high-risk-using-mpc-ab8900e75295",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 22,
    "who": "NHS Digital/Privitar",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller, I want to link data with a dataset held by another party without having to compromise the anonymity of individuals in each dataset",
    "sector": "Health and Social Care",
    "description": "A system for linking patient data held across different NHS domains. To protect patient confidentiality, identifiers (such as a patient's NHS number) are pseudonymised through tokenisation. For additional security, the tokenisation differs between different NHS domains. To link data about a patient held in two domains requires first removing the tokenisation, which would expose personal information. To avoid this, a partially homomorphic encryption scheme is used which enables data to be linked without revealing the underlying raw identifiers.",
    "stage-of-dev": "Product",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "HE",
    "pets2": "De-ID",
    "pets3": "",
    "link1": "Royal Society report on PETs",
    "link2": "",
    "link3": "",
    "link1URL": "https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "#data_linking",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 23,
    "who": "NVIDIA and King's College London",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "In 2019, researchers from NVIDIA and KCL collobarted to train a neural network for brain tumour segmentation using a federated learning approach. They used a dataset from the BraTS Challenge 2018, containing MRI scans from 285 patients, using 242 patients as training data, and 43 patients for testing. Training data was split into 13 shards, each representing a client in the federated setup. A data-centralised model was also trained for comparison. The data-centralised model converged in ~300 training epochs, with 205s per epoch. The federated model: converged in ~600 training epochs, with ~65s per epoch (slowest client). The model perforance is comparable between the two setups, although the federated model incurs a tradeoff between privacy and performance, determined by the parameters of the differential privacy setup.",
    "stage-of-dev": "Pilot",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "FA",
    "pets2": "DP",
    "pets3": "",
    "link1": "VentureBeat",
    "link2": "",
    "link3": "",
    "link1URL": "https://venturebeat.com/2019/10/13/nvidia-uses-federated-learning-to-create-medical-imaging-ai/",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 24,
    "who": "OpenSAFELY",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "A secure analytics platform developed in response to the COVID-19 pandemic, which enables researchers to conduct analysis across millions of patients' electronic health records (EHR). The platform works by leveraging federated analysis, where researchers' analytic code is uploaded to the datacenter where EHR data is kept. The code is executed in the datacenter, with the data kept in situ - data is never moved from where it was originally kept. Researchers are thus unable to download data, mitigating a key part of the threat model. The platform provides researchers with dummy data (NOT synethic data) to develop their code. Once developed, the code must pass a series of automated sanity checks, before it is packaged into a Docker container which is deployed to the EHR provider's datacenter to execute tha analysis. OpenSAFELY has enabled risk factors associated with COVID-19 to be identified, without exposing the personal information of individuals. ",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "FA",
    "pets2": "De-ID",
    "pets3": "",
    "link1": "OpenSAFELY website",
    "link2": "Nature paper",
    "link3": "",
    "link1URL": "https://opensafely.org/",
    "link2URL": "https://www.nature.com/articles/s41586-020-2521-4",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 25,
    "who": "Owkin",
    "use-case-type": "",
    "use-case-sub-type": "",
    "sector": "Health and Social Care",
    "description": "French-American startup, Owkin, is using Federated Learning to build an AI-Severity score that predicts the severity of a patient's COVID-19 prognosis. The model is trained on a CT scans of lungs (a routine procedure upon admission to hospital for COVID-19 patients). Its performance surpasses that of all other published score benchmarks. These scores support hospitals in resource management and planning at the frontline. ",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "MPC",
    "pets2": "",
    "pets3": "",
    "link1": "Imaging Technology News",
    "link2": "Nature Communications (model publication)",
    "link3": "",
    "link1URL": "https://www.itnonline.com/content/integrating-deep-learning-ct-scan-model-helps-predict-severity-covid-19-patients",
    "link2URL": "https://www.nature.com/articles/s41467-020-20657-4",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 26,
    "who": "Privitar",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "",
    "sector": "Finance",
    "description": "With the use of partial homomorphic encryption, this pilot project allows financial institutions to learn statistics about a population from disparate private and public datasets without collecting any identifiable information. In this process, the recipient analyses multiple datasets where the raw data is presented in tokenised form. The results of this project would enable a public authority to gather aggregate statistics about a population which would inform public policy in a privacy-preserving way. Even if a party intercepts the data at any point in the process, they would not be able to decrypt or link the various datasets. ",
    "stage-of-dev": "Pilot",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "",
    "pets3": "",
    "link1": "RUSI-FFIS report (Chapter 7)",
    "link2": "",
    "link3": "",
    "link1URL": "https://www.gcffc.org/wp-content/uploads/2020/06/FFIS-Innovation-and-discussion-paper-Case-studies-of-the-use-of-privacy-preserving-analysis.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 27,
    "who": "Signal",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller, I want to link data with a dataset held by another party without having to compromise the anonymity of individuals in each dataset",
    "sector": "Digital",
    "description": "Signal is an open-source, privacy-focused instant messaging app. Signal provides end-to-end encryption of messages, and beyond this aims to collect as little information about its users as possible: the only information stored is a user's phone number, as this is required to register with the service. Signal leverages novel security technologies in order to provide features expected by users without collecting data about them. One such example is their use of trusted execution environments (namely, Intel SGX) to allow contact information from a user's phone to be used to find their contacts who are also on Signal. A server-side contact discovery service runs inside the TEE, to which a user uploads their contact information, the service looks for matches in Signal's database of registered users, and information of these matches is returned to the user. Contact information is only decrypted inside the isolated TEE, meaning Signal has no visibility of it. Additionally, SGX supports remote attestation, meaning the client is able to verify that it is the expected contact discovery service code running inside the TEE before using it.",
    "stage-of-dev": "Pilot",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "x",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "TEE",
    "pets2": "",
    "pets3": "",
    "link1": "Signal blog",
    "link2": "GitHub source code",
    "link3": "",
    "link1URL": "https://signal.org/blog/private-contact-discovery/",
    "link2URL": "https://github.com/signalapp/ContactDiscoveryService/",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 28,
    "who": "Tsinghua University and Microsoft",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "Medical Named Entity Recognition (NER) is an NLP task which aims to identify entities (e.g. drug names, symptoms) from unstructured medical texts (e.g. patient records, doctor's notes). Microsoft collaborated with Tsinghua University to develop a federated system named FedNER to train a machine learning model to perform NER on a corpus of data held across a number of medical platforms. The model was decomposed into a private local model, and a global shared model. Different medical platforms storing information in different formats are able to train the local model without having to wrangle their data into a defined format. This lowers the barrier to participation for any individual medical platform, maximising the amount of data used to train the system, thus enhancing its performance.",
    "stage-of-dev": "Pilot",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "FA",
    "pets2": "",
    "pets3": "",
    "link1": "Research paper",
    "link2": "",
    "link3": "",
    "link1URL": "https://arxiv.org/pdf/2003.09288.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 29,
    "who": "US Census Bureau",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller/processor, I want to be able to share aggregate data/statistics with a party/parties/the public such that personal information in the dataset cannot be reverse-engineered",
    "sector": "Other",
    "description": "The Bureau plans to leverage differential privacy to minimise the risk of identification of individuals when publishing statistics from the 2020 Census. The total population in each state will be as counted, but all other levels of geography - including congressional districts down to townships and census blocks - could have some variance from the raw data as a result of noise-injection to facilitate DP. Setting the value of the privacy budget ε has not been trivial. The value chosen by the Census Bureau’s Data Stewardship Executive Policy committee was far higher than those envisioned by the creators of differential privacy. There are further challenges, with the National Congress of Native Americans expressing concern that DP could adversely affect the quality of statistics about tribal nations.",
    "stage-of-dev": "In development",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "DP",
    "pets2": "",
    "pets3": "",
    "link1": "Royal Society report on PETs",
    "link2": "Report on issues encountered implementing DP",
    "link3": "Explainer by the National Conference of State Legislators",
    "link1URL": "https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf",
    "link2URL": "https://arxiv.org/pdf/1809.02201.pdf",
    "link3URL": "https://www.ncsl.org/research/redistricting/differential-privacy-for-census-data-explained.aspx",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  }
 ]