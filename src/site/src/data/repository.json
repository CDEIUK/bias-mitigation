[
  {
    "unique-id": 1,
    "who": "AUSTRAC",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "As a regulator, I want to identify illegal online activity that is coordinated across institutions, whilst ensuring that sensitive information held by each institution is not revealed",
    "sector": "Finance",
    "description": "Developing federated system to identify suspicious financial activities carried out by individuals or groups across a number of financial institutions. Aim to be able to gather insights from over 100 million accounts.",
    "stage-of-dev": "In development",
    "he": "x",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "MPC",
    "pets3": "",
    "link1": "LinkedIn",
    "link2": "FFIS",
    "link3": "",
    "link1URL": "https://www.linkedin.com/pulse/australia-unveils-world-first-privacy-preserving-fintel-nathan-lynch/",
    "link2URL": "https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_innovation_and_discussion_paper_-_case_studies_of_the_use_of_privacy_preserving_analysis.pdf",
    "link3URL": "",
    "kw1": "#fraud",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 2,
    "who": "Duality Technologies",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "A framework for genome-wide association studies that leverages homomorphic encryption to keep medical and genomic data secure. The framework has been applied to conduct GWAS of age-related macular degeneration on a dataset of over 25,000 individuals. The sytem is ~30 times faster than state of the art GWAS schemes based on multi-party computation.",
    "stage-of-dev": "Proof of concept",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "HE",
    "pets2": "",
    "pets3": "",
    "link1": "Original paper",
    "link2": "PR Newswire",
    "link3": "",
    "link1URL": "https://www.pnas.org/content/117/21/11608",
    "link2URL": "https://www.prnewswire.com/il/news-releases/duality-technologies-researchers-accelerate-privacy-enhanced-collaboration-on-genomic-data--with-significant-implications-for-covid-19-research-301059258.html",
    "link3URL": "",
    "kw1": "#GWAS",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 3,
    "who": "NHS Digital/Privitar",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller, I want to link data with a dataset held by another party without having to compromise the anonymity of individuals in each dataset",
    "sector": "Health and Social Care",
    "description": "A system for linking patient data held across different NHS domains. To protect patient confidentiality, identifiers (such as a patient's NHS number) are pseudonymised through tokenisation. For additional security, the tokenisation differs between different NHS domains. To link data about a patient held in two domains requires first removing the tokenisation, which would expose personal information. To avoid this, a partially homomorphic encryption scheme is used which enables data to be linked without revealing the underlying raw identifiers.",
    "stage-of-dev": "Product",
    "he": "x",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "HE",
    "pets2": "De-ID",
    "pets3": "",
    "link1": "Royal Society report on PETs",
    "link2": "",
    "link3": "",
    "link1URL": "https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "#data_linking",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 4,
    "who": "Google",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller/processor, I want to be able to share aggregate data/statistics with a party/parties/the public such that personal information in the dataset cannot be reverse-engineered",
    "sector": "Health and Social Care",
    "description": "A publicly available resource of statistics and visualisations intended to show the changes in the population’s mobility habits in response to COVID-19 interventions, based on location data from Google users opted in to location history tracking. Differential privacy is used to protect two metrics: the details of the location a user visited, and the number of visits the user made to each location.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "DP",
    "pets2": "",
    "pets3": "",
    "link1": "Google blog",
    "link2": "Technical paper",
    "link3": "",
    "link1URL": "https://www.blog.google/technology/health/covid-19-community-mobility-reports",
    "link2URL": "https://arxiv.org/pdf/2004.04145.pdf",
    "link3URL": "",
    "kw1": "#COVID",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 5,
    "who": "Estonian Association of Information Technology and Telecommunications (ITL)",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "As an economist/policy advisor/minister, I want to derive performance metrics about a sector, whilst preserving the privacy of commercially sensitive information held by organisations in that sector",
    "sector": "Other",
    "description": "In 2011, ITL proposed collecting key financial metrics from its member companies in order to better understand the state of the telecoms sector. Members expressed concern over the confidentiality of the metrics, as they would be sharing them with competitors. ITL chose to partner with cybersecurity firm Cybernetica, who were able to deploy their Sharemind secure computing platform to enable the analysis to be done whilst protecting confidentiality. 17 companies participated, uploading their metrics to the Sharemind platform, which distributed the data across three “computing parties” (CPs). These CPs performed the desired analysis, using a multi-party computation protocol to ensure confidentiality. The final results of the analysis were shared with the ITL, who disseminated accordingly. The distributed nature of the computation meant no party, including the ITL, ever had direct access to another party’s metrics.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "MPC",
    "pets2": "",
    "pets3": "",
    "link1": "Royal Society report on PETs",
    "link2": "Academic paper",
    "link3": "",
    "link1URL": "https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf",
    "link2URL": "https://academic.oup.com/comjnl/article/61/12/1749/5095655",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 6,
    "who": "Google",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to to train personalised systems without having to gather personal data from individuals",
    "sector": "Digital",
    "description": "GBoard is a keyboard app for Android and iOS devices. It features next-word prediction, driven by a machine learning model. GBoard utilises federated learning, where each mobile device downloads an initial model from a central server, which is further trained on the device using user data local to the device. The weights of the resulting model are periodically communicated back to the central server using a secure aggregation protocol (a form of multi-party computation), which aggregates the weights received from all mobile devices into a new common model. Devices download this new model, and the cycle repeats, such that the model is continuously trained without collecting user data centrally.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "x",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "MPC",
    "pets2": "FA",
    "pets3": "",
    "link1": "Google blog",
    "link2": "Technical paper",
    "link3": "",
    "link1URL": "https://ai.googleblog.com/2017/04/federated-learning-collaborative.html",
    "link2URL": "https://arxiv.org/pdf/1811.03604.pdf",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 7,
    "who": "Danisco and the Association of Sugar Beet Growers",
    "use-case-type": "collaborative_data_analysis",
    "use-case-sub-type": "As an economist/policy advisor/minister, I want to derive performance metrics about a sector, whilst preserving the privacy of commercially sensitive information held by organisations in that sector",
    "sector": "Other",
    "description": "Sugar beet farmers in Denmark have contracts determining how much beet they produce. All beet produced goes to Danisco, the only sugar producer in Denmark. The EU significantly reduced beet subsidies, meaning the country needed to develop a competitive market for trading production rights. A system was developed leveraging multi-party computation to enable confidential bidding to compute a trading price based on supply and demand. This enabled the production quota to be redistributed accordingly, whilst details of individual beet farmers bids remained confidential - 80% of farmers surveyed that this confidentiality was important to them. The first auction took place in 2008, and is considered the first large-scale, practical application of MPC.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "x",
    "fa": "",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "MPC",
    "pets2": "",
    "pets3": "",
    "link1": "Report",
    "link2": "",
    "link3": "",
    "link1URL": "https://eprint.iacr.org/2008/068.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 8,
    "who": "Microsoft",
    "use-case-type": "secure_data_processing",
    "use-case-sub-type": "As a data controller and processor, I want to conduct my own processing within an environment that I do not fully trust, such as a cloud provider’s infrastructure",
    "sector": "Digital",
    "description": "The Confidential Consortium Blockchain Framework (CCBF) is a system using trusted execution environments that facilitates confidentiality within a blockchain network. To prevent malicious behaviours, blockchains were designed so that all transactions are recorded and open for all to see and replicated across hundreds of decentralised nodes for integrity. Within CCBF, confidentiality is provided by TEEs that can process transactions encrypted using keys accessible only to a CCBF node of a specific CCBF service. Besides confidentiality, TEEs also provide publicly verifiable artefacts, called quotes, that certify that the TEE is running a specific code. Hence, integrity of transaction evaluation in CCBF can be verified via quotes and not be replicated across mutually untrusted nodes as it is done in public blockchains. It is worth pointing out that transaction data is replicated in CCBF across a small network of nodes, each executing in a TEE, but for the purpose of fault-tolerance rather than integrity. In addition, Microsoft’s test showed that the CCBF could process 50,000+ transactions per second, demonstrating the scalability of the technology. As a comparison, the public blockchain Ethereum network has an average processing rate of 20 transactions per second, whilst the Visa credit card processing system averages 2,000 transactions per second.  The framework is not a standalone blockchain protocol, but rather it provides trusted foundations that can support any existing blockchain protocol.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "x",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "TEE",
    "pets2": "",
    "pets3": "",
    "link1": "Royal Society report on PETs",
    "link2": "GitHub repository",
    "link3": "Technical report",
    "link1URL": "https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf",
    "link2URL": "https://github.com/Microsoft/CCF",
    "link3URL": "https://github.com/microsoft/CCF/blob/main/CCF-TECHNICAL-REPORT.pdf",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 9,
    "who": "US Census Bureau",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller/processor, I want to be able to share aggregate data/statistics with a party/parties/the public such that personal information in the dataset cannot be reverse-engineered",
    "sector": "Other",
    "description": "The Bureau plans to leverage differential privacy to minimise the risk of identification of individuals when publishing statistics from the 2020 Census. The total population in each state will be as counted, but all other levels of geography - including congressional districts down to townships and census blocks - could have some variance from the raw data as a result of noise-injection to facilitate DP. Setting the value of the privacy budget ε has not been trivial. The value chosen by the Census Bureau’s Data Stewardship Executive Policy committee was far higher than those envisioned by the creators of differential privacy. There are further challenges, with the National Congress of Native Americans expressing concern that DP could adversely affect the quality of statistics about tribal nations.",
    "stage-of-dev": "In development",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "DP",
    "pets2": "",
    "pets3": "",
    "link1": "Royal Society report on PETs",
    "link2": "Report on issues encountered implementing DP",
    "link3": "Explainer by the National Conference of State Legislators",
    "link1URL": "https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf",
    "link2URL": "https://arxiv.org/pdf/1809.02201.pdf",
    "link3URL": "https://www.ncsl.org/research/redistricting/differential-privacy-for-census-data-explained.aspx",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 10,
    "who": "Apple/Google contact tracing API",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "Developed in response to the COVID-19 pandemic, Apple and Google collaborated to develop a privacy-preserving architecture facilitating digital contract tracing based on bluetooth proximity information. Access to the system is only made available to health authorities, who develop their own apps leveraging the Apple/Google APIs (for example the NHS app in England Wales). Mobiles phones with the app enabled exchange random identifiers (each phone's identifier changes frequently) when in close proximity. Following a positive test, a user consents to upload details of their device's identifiers from recent days to a central server managed by the health authority. All phones periodically download this list of identifiers corresponding to positive tests from the central server, and receive an alert to self-isolate if there is a match with the identifiers of close contacts stored on their device. ",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "FA",
    "pets2": "De-ID",
    "pets3": "",
    "link1": "Google",
    "link2": "Apple",
    "link3": "",
    "link1URL": "https://www.google.com/covid19/exposurenotifications/#exposure-notifications-and-privacy",
    "link2URL": "https://covid19.apple.com/contacttracing",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 11,
    "who": "OpenSAFELY",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "A secure analytics platform developed in response to the COVID-19 pandemic, which enables researchers to conduct analysis across millions of patients' electronic health records (EHR). The platform works by leveraging federated analysis, where researchers' analytic code is uploaded to the datacenter where EHR data is kept. The code is executed in the datacenter, with the data kept in situ - data is never moved from where it was originally kept. Researchers are thus unable to download data, mitigating a key part of the threat model. The platform provides researchers with dummy data (NOT synethic data) to develop their code. Once developed, the code must pass a series of automated sanity checks, before it is packaged into a Docker container which is deployed to the EHR provider's datacenter to execute tha analysis. OpenSAFELY has enabled risk factors associated with COVID-19 to be identified, without exposing the personal information of individuals. ",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "x",
    "pets1": "FA",
    "pets2": "De-ID",
    "pets3": "",
    "link1": "OpenSAFELY website",
    "link2": "Nature paper",
    "link3": "",
    "link1URL": "https://opensafely.org/",
    "link2URL": "https://www.nature.com/articles/s41586-020-2521-4",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 12,
    "who": "Tsinghua University and Microsoft",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to experiment with and train systems to perform valuable tasks which require highly sensitive data",
    "sector": "Health and Social Care",
    "description": "Medical Named Entity Recognition (NER) is an NLP task which aims to identify entities (e.g. drug names, symptoms) from unstructured medical texts (e.g. patient records, doctor's notes). Microsoft collaborated with Tsinghua University to develop a federated system named FedNER to train a machine learning model to perform NER on a corpus of data held across a number of medical platforms. The model was decomposed into a private local model, and a global shared model. Different medical platforms storing information in different formats are able to train the local model without having to wrangle their data into a defined format. This lowers the barrier to participation for any individual medical platform, maximising the amount of data used to train the system, thus enhancing its performance.",
    "stage-of-dev": "Pilot",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "FA",
    "pets2": "",
    "pets3": "",
    "link1": "Research paper",
    "link2": "",
    "link3": "",
    "link1URL": "https://arxiv.org/pdf/2003.09288.pdf",
    "link2URL": "",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 13,
    "who": "Facebook",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller/processor, I want to be able to share aggregate data/statistics with a party/parties/the public such that personal information in the dataset cannot be reverse-engineered",
    "sector": "Digital",
    "description": "In 2018, Facebook established an initiative to provide researchers access to data in order to study the role of social media in elections and democratic discourse. Data was shared with 60 researchers, and consisted of links that had been shared publicly on Facebook by at least 100 unique Facebook users. In 2020, the size of the shared dataset was substantially increased to include approximately 38 million such links, with new aggregated information to help researchers analyze how many people saw these links on Facebook and how they interacted with that content – including views, clicks, shares, likes, and other reactions. The data shared was also aggregated by age, gender, country, and month. Facebook leveraged differential privacy to provide privacy guarantees to individuals in the dataset.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "DP",
    "pets2": "",
    "pets3": "",
    "link1": "Facebook blog",
    "link2": "Technical report",
    "link3": "",
    "link1URL": "https://research.fb.com/blog/2020/02/new-privacy-protected-facebook-data-for-independent-research-on-social-medias-impact-on-democracy/",
    "link2URL": "https://arxiv.org/pdf/2002.04049.pdf",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 14,
    "who": "Apple",
    "use-case-type": "privacy_preserving_data_science",
    "use-case-sub-type": "As a data scientist, I want to to train personalised systems without having to gather personal data from individuals",
    "sector": "Digital",
    "description": "Apple has leveraged federated learning to train the voice recognition software used by its AI Assistant, Siri. A local model is trained on an individual's iPhone, and the resulting model weights are periodically communicated back to a central server, which builds a global model by aggregating the weights from the local models. This global model is pushed out to users' iPhones, and the process repeats. Noise is injected during the training of the local model to ensure it is differentially private, so as to mitigate the risk of reidentification. Using this system, Siri can learn to recognise the voice of the iPhone owner, so that it only responds to them, without Apple collecting any raw data relating to the users' voice.",
    "stage-of-dev": "Product",
    "he": "",
    "mpc": "",
    "fa": "x",
    "tee": "",
    "dp": "x",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "FA",
    "pets2": "DP",
    "pets3": "",
    "link1": "MIT Tech Review",
    "link2": "Apple: Learning with privacy at scale",
    "link3": "",
    "link1URL": "https://www.technologyreview.com/2019/12/11/131629/apple-ai-personalizes-siri-federated-learning/",
    "link2URL": "https://machinelearning.apple.com/research/learning-with-privacy-at-scale",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  },
  {
    "unique-id": 15,
    "who": "Signal",
    "use-case-type": "data_sharing",
    "use-case-sub-type": "As a data controller, I want to link data with a dataset held by another party without having to compromise the anonymity of individuals in each dataset",
    "sector": "Digital",
    "description": "Signal is an open-source, privacy-focused instant messaging app. Signal provides end-to-end encryption of messages, and beyond this aims to collect as little information about its users as possible: the only information stored is a user's phone number, as this is required to register with the service. Signal leverages novel security technologies in order to provide features expected by users without collecting data about them. One such example is their use of trusted execution environments (namely, Intel SGX) to allow contact information from a user's phone to be used to find their contacts who are also on Signal. A server-side contact discovery service runs inside the TEE, to which a user uploads their contact information, the service looks for matches in Signal's database of registered users, and information of these matches is returned to the user. Contact information is only decrypted inside the isolated TEE, meaning Signal has no visibility of it. Additionally, SGX supports remote attestation, meaning the client is able to verify that it is the expected contact discovery service code running inside the TEE before using it.",
    "stage-of-dev": "Pilot",
    "he": "",
    "mpc": "",
    "fa": "",
    "tee": "x",
    "dp": "",
    "zkp": "",
    "sd": "",
    "de-id": "",
    "pets1": "TEE",
    "pets2": "",
    "pets3": "",
    "link1": "Signal blog",
    "link2": "GitHub source code",
    "link3": "",
    "link1URL": "https://signal.org/blog/private-contact-discovery/",
    "link2URL": "https://github.com/signalapp/ContactDiscoveryService/",
    "link3URL": "",
    "kw1": "",
    "kw2": "",
    "kw3": ""
  }
 ]