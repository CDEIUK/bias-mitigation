---
title: Additional Resources
---

import CookieBanner from "../components/cookies"
import OutboundLink from "../components/outbound-link"

<CookieBanner />

The Royal Society's 2019 report <OutboundLink href="https://royalsociety.org/-/media/policy/projects/privacy-enhancing-technologies/privacy-enhancing-technologies-report.pdf">Protecting Privacy in Practice</OutboundLink> provides case studies for a number of the emerging PETs discussed on this site, as well as Personal Data Store technology. The Royal Society will refresh their report in 2021 **(TODO: confirm with Franck what we can say here)**.

The ICO has produced a <OutboundLink href="https://ico.org.uk/for-organisations/data-sharing-information-hub/">Data Sharing Code of Practice</OutboundLink>, and have released a <OutboundLink href="https://ico.org.uk/about-the-ico/news-and-events/blog-building-on-the-data-sharing-code-our-plans-for-updating-our-anonymisation-guidance/">roadmap</OutboundLink> for updating their guidance on anonymisation and pseudonymisation which will explore the role that privacy enhancing technologies might play in enabling safe and lawful data sharing. Some guidance is already provided in a machine learning context in the ICO's <OutboundLink href="https://ico.org.uk/for-organisations/guide-to-data-protection/key-data-protection-themes/guidance-on-ai-and-data-protection/how-should-we-assess-security-and-data-minimisation-in-ai/#whatdataminimisation">guidance on AI and data protection</OutboundLink>.

In the finance sector, the <OutboundLink href="https://www.future-fis.com">Future of Financial Intelligence Sharing</OutboundLink> (FFIS) programme is researching the role of PETs in the detection and prevention of financial crime. FFIS has explored a number of case studies, several of which are included in our repsitory, which are described in detail in their <OutboundLink href="https://www.future-fis.com/uploads/3/7/9/4/3794525/ffis_innovation_and_discussion_paper_-_case_studies_of_the_use_of_privacy_preserving_analysis_-_v.1.3.pdf">discussion paper</OutboundLink>.

Open-source community <OutboundLink href="https://www.openmined.org/">OpenMined</OutboundLink> is developing tooling to lower the barrier-to-entry to private AI technologies. OpenMined's software extends popular machine learning libraries such as PyTorch with advanced cryptographic techniques and differential privacy. OpenMined is also providing education in this area through freely available online courses. The <OutboundLink href="https://courses.openmined.org/courses/our-privacy-opportunity">Our Privacy Opportunity</OutboundLink> course provides a short overview of privacy-preserving AI requiring no technical knowledge or coding skills, and the <OutboundLink href="https://courses.openmined.org/courses/foundations-of-private-computation">Foundations of Private Computation</OutboundLink> course provides hands-on learning for developers, only requiring beginner knowledge of Python.

The <OutboundLink href="https://www.rephrain.ac.uk/">National Research Centre on Privacy, Harm Reduction and Adversarial Influence Online</OutboundLink> (REPHRAIN) was established by UKRI in 2020 and brings together academics and researchers from the universities of Bristol, Edinburgh, Bath, Kingâ€™s College London, and University College London. The Centre is taking an interdisciplinary approach to researching online harms, and the role PETs could play in this. Of particular interest is the creation of a <OutboundLink href="https://www.rephrain.ac.uk/rephrain-toolbox/">PETs Testbed</OutboundLink>, incorporating network and end-nodes on which PETs will be rolled out and evaluated, both from the systems and human experiences viewpoint.
