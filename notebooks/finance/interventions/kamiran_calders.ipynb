{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reweighting by Kamiran and Calders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an implementation of the pre-processing fairness intervention introduced in [Data preprocessing techniques for classification without discrimination](https://link.springer.com/article/10.1007/s10115-011-0463-8) by Kamiran and Calders (2012) as part of the IBM AIF360 fairness tool box github.com/IBM/AIF360.\n",
    "\n",
    "The intervention achieves demographic parity by attaching weights to the data so that certain types of observations are more influential during training, thereby balancing out the label distributions across different protected groups. The resulting weights can also be used to resample the data set with replacement to create a fair transformed data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from helpers.fairness_measures import accuracy\n",
    "from helpers.plot import group_box_plots\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We have committed preprocessed data to the repository for reproducibility and we load it here. Check out hte preprocessing notebook for details on how this data was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"adult\"\n",
    "\n",
    "train = pd.read_csv(data_dir / \"processed\" / \"train-one-hot.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val-one-hot.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test-one-hot.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process data for our fairness intervention we need to define special dataset objects which are part of every intervention pipeline within the IBM AIF360 toolbox. These objects contain the original data as well as some useful further information, e.g., which feature is the protected attribute as well as which column corresponds to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which binary value goes with the (un-)privileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"sex\": 1.0}]\n",
    "unprivileged_groups = [{\"sex\": 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For maximum reproducibility we can also load the baseline model from disk, but the code used to train can be found in the baseline model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_model = joblib.load(artifacts_dir / \"models\" / \"finance\" / \"baseline.pkl\")\n",
    "\n",
    "bl_test_probs = bl_model.predict_proba(test.drop(\"salary\", axis=1))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test.sex == 1\n",
    "\n",
    "print(\"Original model accuracy =\", accuracy(bl_test_probs, test.salary))\n",
    "print(\n",
    "    \"Female accuracy =\", accuracy(bl_test_probs[~mask], test.salary[~mask]),\n",
    ")\n",
    "print(\n",
    "    \"Male accuracy =\", accuracy(bl_test_probs[mask], test.salary[mask]),\n",
    ")\n",
    "print(\"Mean female score =\", bl_test_probs[~mask].mean())\n",
    "print(\"Mean male score =\", bl_test_probs[mask].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic parity\n",
    "\n",
    "We learn the data transformation due to Kamiran and Claders on the training data. The transformation attaches fair weights to data it is applied to. A fair data set can then be generated via weighted sampling. We apply the transformation to the validation set, but instead of resampling according to the resulting weights, we train a logisitc regression model using the underlying weights in the validation set. Finally, we generate predictions for the test data based on the leanrnt fair logisitic regression and analyse the outcomes for fairness and accuracy.\n",
    "\n",
    "The intervention does not require any parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn intervention\n",
    "\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "RW.fit(train_sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply intervention\n",
    "\n",
    "On validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sds_transf = RW.transform(val_sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train fairn model\n",
    "\n",
    "We learn a logistic regression model on the validation set incorporating the learnt fair weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fair = LogisticRegression(max_iter=10000)\n",
    "X_val = val_sds_transf.features\n",
    "y_val = val_sds_transf.labels.flatten()\n",
    "model_fair.fit(X_val, y_val, sample_weight=val_sds_transf.instance_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply fair model\n",
    "\n",
    "On test set.\n",
    "\n",
    "Note that the pre-processing intervention of the validation data happens in the model prediction since the model has been based on the weighting which was determined by the reweight transformed validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sds_pred = test_sds.copy(deepcopy=True)\n",
    "X_test = test_sds_pred.features\n",
    "y_test = test_sds.labels\n",
    "test_sds_pred.scores = model_fair.predict_proba(X_test)[:, 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse fairness and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test.sex == 1\n",
    "\n",
    "print(\"Accuracy =\", accuracy(test_sds_pred.scores.flatten(), test.salary))\n",
    "\n",
    "print(\n",
    "    \"Female accuracy =\",\n",
    "    accuracy(test_sds_pred.scores.flatten()[~mask], test.salary[~mask],),\n",
    ")\n",
    "print(\n",
    "    \"Male accuracy =\",\n",
    "    accuracy(test_sds_pred.scores.flatten()[mask], test.salary[mask],),\n",
    ")\n",
    "print(\n",
    "    \"Mean female score =\", test_sds_pred.scores.flatten()[~mask].mean(),\n",
    ")\n",
    "print(\n",
    "    \"Mean male score =\", test_sds_pred.scores.flatten()[mask].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_box = group_box_plots(\n",
    "    np.concatenate([bl_test_probs, test_sds_pred.scores.flatten()]),\n",
    "    np.concatenate(\n",
    "        [\n",
    "            np.zeros_like(bl_test_probs),\n",
    "            np.ones_like(test_sds_pred.scores.flatten()),\n",
    "        ]\n",
    "    ),\n",
    "    np.tile(test.sex.map(lambda x: \"Male\" if x else \"Female\"), 2),\n",
    "    group_names=[\"Baseline\", \"Kamiran-Calders\"],\n",
    ")\n",
    "dp_box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
