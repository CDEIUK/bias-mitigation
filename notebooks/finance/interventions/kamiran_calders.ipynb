{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamiran Calders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from helpers.fairness_measures import accuracy\n",
    "from helpers.finance import preprocess\n",
    "from helpers.plot import group_box_plots\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The `preprocess` function checks if adult data is available and if not downloads and saves it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"adult\"\n",
    "preprocess(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir / \"processed\" / \"train-one-hot.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val-one-hot.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test-one-hot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"salary\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"sex\"],\n",
    "    privileged_classes=[[1]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"sex\": 1.0}]\n",
    "unprivileged_groups = [{\"sex\": 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_model = joblib.load(artifacts_dir / \"models\" / \"finance\" / \"baseline.pkl\")\n",
    "\n",
    "bl_test_probs = bl_model.predict_proba(test.drop(\"salary\", axis=1))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test.sex == 1\n",
    "\n",
    "print(\"Original model accuracy =\", accuracy(bl_test_probs, test.salary))\n",
    "print(\n",
    "    \"Female accuracy =\", accuracy(bl_test_probs[~mask], test.salary[~mask]),\n",
    ")\n",
    "print(\n",
    "    \"Male accuracy =\", accuracy(bl_test_probs[mask], test.salary[mask]),\n",
    ")\n",
    "print(\"Mean female score =\", bl_test_probs[~mask].mean())\n",
    "print(\"Mean male score =\", bl_test_probs[mask].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform intervention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with and transform the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups,\n",
    ")\n",
    "RW.fit(train_sds)\n",
    "train_sds_transf = RW.transform(train_sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with transformed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fair = LogisticRegression(max_iter=10000)\n",
    "X_train = train_sds_transf.features\n",
    "y_train = train_sds_transf.labels.flatten()\n",
    "model_fair.fit(\n",
    "    X_train, y_train, sample_weight=train_sds_transf.instance_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict fairly on test set\n",
    "Note that the pre-processing intervention of the validation data happens in the model prediction since the model has been based on the weighting which was determined by the reweight transformed training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sds_pred = test_sds.copy(deepcopy=True)\n",
    "X_test = test_sds_pred.features\n",
    "y_test = test_sds.labels\n",
    "test_sds_pred.scores = model_fair.predict_proba(X_test)[:, 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse fairness and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = test.sex == 1\n",
    "\n",
    "print(\"Accuracy =\", accuracy(test_sds_pred.scores.flatten(), test.salary))\n",
    "\n",
    "print(\n",
    "    \"Female accuracy =\",\n",
    "    accuracy(test_sds_pred.scores.flatten()[~mask], test.salary[~mask],),\n",
    ")\n",
    "print(\n",
    "    \"Male accuracy =\",\n",
    "    accuracy(test_sds_pred.scores.flatten()[mask], test.salary[mask],),\n",
    ")\n",
    "print(\n",
    "    \"Mean female score =\", test_sds_pred.scores.flatten()[~mask].mean(),\n",
    ")\n",
    "print(\n",
    "    \"Mean male score =\", test_sds_pred.scores.flatten()[mask].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_box = group_box_plots(\n",
    "    np.concatenate([bl_test_probs, test_sds_pred.scores.flatten()]),\n",
    "    np.concatenate(\n",
    "        [\n",
    "            np.zeros_like(bl_test_probs),\n",
    "            np.ones_like(test_sds_pred.scores.flatten()),\n",
    "        ]\n",
    "    ),\n",
    "    np.tile(test.sex.map(lambda x: \"Male\" if x else \"Female\"), 2),\n",
    "    group_names=[\"Baseline\", \"Kamiran-Calders\"],\n",
    ")\n",
    "dp_box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
