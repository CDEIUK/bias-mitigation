{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision threshold modification by Hardt et al. - Recruiting data\n",
    "\n",
    "This notebook contains an implementation of the post-processing fairness intervention introduced in [Equality of opportunity in supervised learning](https://dl.acm.org/doi/10.5555/3157382.3157469) by Hardt et al. (2016) as part of the IBM AIF360 fairness tool box github.com/IBM/AIF360.\n",
    "\n",
    "The intervention method achieves equalised odds as follows. If only the decisions are available, they randomly choose either the original decision or fixed outcome in a way that ensures agreement across both protected groups. If a score function is available they choose between two carefully chosen thresholds with a particular probability to ensure agreement of true and false positive rates.\n",
    "\n",
    "This method can be proven to be the optimal postprocessing algorithm for Equalised Odds, however the randomness introduced into decision making - which in particular could mean two identical individuals receive different outcomes - might clash with intuitive notions of fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.postprocessing.eq_odds_postprocessing import (\n",
    "    EqOddsPostprocessing,\n",
    ")\n",
    "from helpers.fairness_measures import accuracy, equalised_odds_p\n",
    "from sklearn.neural_network import MLPClassifier  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We have committed preprocessed data to the repository for reproducibility and we load it here. Check out hte preprocessing notebook for details on how this data was obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of artifacts (model and data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = Path(\"../../../artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = artifacts_dir / \"data\" / \"recruiting\"\n",
    "\n",
    "train = pd.read_csv(data_dir / \"processed\" / \"train.csv\")\n",
    "val = pd.read_csv(data_dir / \"processed\" / \"val.csv\")\n",
    "test = pd.read_csv(data_dir / \"processed\" / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process data for our fairness intervention we need to define special dataset objects which are part of every intervention pipeline within the IBM AIF360 toolbox. These objects contain the original data as well as some useful further information, e.g., which feature is the protected attribute as well as which column corresponds to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sds = StandardDataset(\n",
    "    train,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "test_sds = StandardDataset(\n",
    "    test,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "val_sds = StandardDataset(\n",
    "    val,\n",
    "    label_name=\"employed_yes\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"race_white\"],\n",
    "    privileged_classes=[[1]],\n",
    ")\n",
    "index = train_sds.feature_names.index(\"race_white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which binary value goes with the (un-)privileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{\"race_white\": 1.0}]\n",
    "unprivileged_groups = [{\"race_white\": 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original model\n",
    "\n",
    "For maximum reproducibility we load the baseline model from disk, but the code used to train can be found in the baseline model notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_model = joblib.load(\n",
    "    artifacts_dir / \"models\" / \"recruiting\" / \"baseline.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bl_model = MLPClassifier(hidden_layer_sizes=(100, 100), early_stopping=True)\n",
    "# bl_model.fit(train.drop(columns=\"employed_yes\"), train.employed_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prediction for validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_val_pred = bl_model.predict(val.drop(\"employed_yes\", axis=1))\n",
    "val_sds_pred = val_sds.copy(deepcopy=True)\n",
    "val_sds_pred.labels = bl_val_pred.reshape(-1, 1)\n",
    "\n",
    "bl_test_pred = bl_model.predict(test.drop(\"employed_yes\", axis=1))\n",
    "test_sds_pred = test_sds.copy(deepcopy=True)\n",
    "test_sds_pred.labels = bl_test_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalised odds\n",
    "Given the original unfair model we apply Hardt et al.'s intervention to achieve equalised odds. More precisely, we learn the mitigation procedure based on the true and predicted labels of the validation data. The learning does not need any parameter tuning. We then apply the learnt procedure to the predictions of the test data and analyse the outcomes for fairness and accuracy.\n",
    "\n",
    "Note that this intervention method does not allow for a continuous trade-off between fairness and accuracy. Instead, the output is a single combination of accuracy and fairness for the corrected predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn intervention\n",
    "\n",
    "On validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "eopp = EqOddsPostprocessing(\n",
    "    privileged_groups=privileged_groups,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    seed=np.random.seed(),\n",
    ")\n",
    "eopp = eopp.fit(val_sds, val_sds_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply intervention\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sds_pred_tranf = eopp.predict(test_sds_pred)\n",
    "test_sds_pred_tranf.scores = test_sds_pred_tranf.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse fairness and accuracy\n",
    "On test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnr = np.abs(\n",
    "    test_sds_pred_tranf.scores[\n",
    "        (test.employed_yes == 1) & (test.race_white == 1)\n",
    "    ].mean()\n",
    "    - test_sds_pred_tranf.scores[\n",
    "        (test.employed_yes == 1) & (test.race_white == 0)\n",
    "    ].mean()\n",
    ")\n",
    "fpr = np.abs(\n",
    "    test_sds_pred_tranf.scores[\n",
    "        (test.employed_yes == 0) & (test.race_white == 1)\n",
    "    ].mean()\n",
    "    - test_sds_pred_tranf.scores[\n",
    "        (test.employed_yes == 0) & (test.race_white == 0)\n",
    "    ].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Accuracy =\",\n",
    "    accuracy(test_sds_pred_tranf.scores.flatten(), test.employed_yes),\n",
    ")\n",
    "print(\n",
    "    \"Female accuracy =\",\n",
    "    accuracy(\n",
    "        test_sds_pred_tranf.scores.flatten()[test.race_white == 0],\n",
    "        test.employed_yes[test.race_white == 0],\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"Male accuracy =\",\n",
    "    accuracy(\n",
    "        test_sds_pred_tranf.scores.flatten()[test.race_white == 1],\n",
    "        test.employed_yes[test.race_white == 1],\n",
    "    ),\n",
    ")\n",
    "print(\"FNR =\", fnr)\n",
    "print(\"FPR =\", fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Equalised odds = \",\n",
    "    equalised_odds_p(\n",
    "        test_sds_pred_tranf.scores.flatten(),\n",
    "        test.race_white,\n",
    "        test.employed_yes,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_bar = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(\n",
    "            x=[label],\n",
    "            y=[\n",
    "                test_sds_pred_tranf.scores[\n",
    "                    (test.race_white == sex) & (test.employed_yes == label)\n",
    "                ].mean()\n",
    "            ],\n",
    "            name=\"White\" if sex else \"Black\",\n",
    "        )\n",
    "        for label in range(2)\n",
    "        for sex in range(2)\n",
    "    ]\n",
    ")\n",
    "eo_bar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdei",
   "language": "python",
   "name": "cdei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
